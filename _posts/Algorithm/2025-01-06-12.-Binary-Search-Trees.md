---
title: 12. Binary Search Trees
# description: Short summary of the post
date: 2024-12-12 21:27
categories: [Computer Science, Algorithm]
tags: [binary-search-tree]     # TAG names should always be lowercase
math: true
pin: false
---

The search tree data structure supports many dynamic-set operations, including SEARCH, MINIMUM, MAXIMUM, PREDECESSOR, SUCCESSOR, INSERT, and DELETE.
We can use a search tree both as a dictionary and as a priority queue.  
Basic operations on a binary search tree take time proportional to the height of the tree.
For a complete binary tree with $$ n $$ nodes, such operations run in $$ \Theta(\lg n) $$ worst-case time.
If the tree is a linear chain of $$ n $$ nodes, however, the same operations run in $$ \Theta(\lg n) $$ worst-case time.
Since the expected height of a randomly built binary search tree is $$ O(\lg n) $$, so that basic dynamic-set operations on such a tree take $$ \Theta(\lg n) $$ time on average.

## 12.1 What is a binary search tree?

![Desktop View](/assets/img/12-Binary-Search-Trees/Figure 12.1.png){: width="700"}
_**Figure 12.1** An example of a binary search tree._

A binary search tree is organized, as the name suggests, in a binary tree.
We can represent such a tree by a linked data structure in which each node is an object.
In addition to a key and satellite data, each node contains attributes $$ left $$, $$ right $$, and $$ p $$ that point to the nodes corresponding to its left child, its right child, and its parent, respectively.  
The keys in a binary search tree are always stored in such a way as to satisfy the binary-search-tree property:

>Let $$ x $$ be a node in a binary search tree.
>If $$ y $$ is a node in the left subtree of $$ x $$, then $$ y.key \le x.key $$.
>If $$ y $$ is a node in the right subtree of $$ x $$, then $$ y.key \ge x.key $$.

The binary-search-tree property allows us to print out all the keys in a binary search tree in sorted order by a simple recursive algorithm, called an inorder tree walk.
This algorithm prints the key of the root of a subtree between printing the values in its left subtree and printing those in its right subtree.
Similarly, a preorder tree walk prints the root before the values in either subtree, and a postorder tree walk prints the root after the values in its subtrees.

>INORDER-TREE-WALK($$ x $$)  
>01&nbsp; if $$ x \neq $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;INORDER-TREE-WALK($$ x.left $$)  
>03&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;print $$ x.key $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;INORDER-TREE-WALK($$ x.right $$)  

The correctness of the algorithm follows by induction directly from the binary-search-tree property.
It takes $$ \Theta(n) $$ time to walk an $$ n $$-node binary search tree, since after the initial call, the procedure calls itself recursively exactly twice for each node in the tree—once for its left child and once for its right child.

### Theorem 12.1

If $$ x $$ is the root of an $$ n $$-node subtree, then the call INORDER-TREE-WALK($$ x $$) takes $$ \Theta(n) $$ time.

**Proof**  
Let $$ T(n) $$ denote the time taken by INORDER-TREE-WALK when it is called on the root of an $$ n $$-node subtree.
Since INORDER-TREE-WALK visits all $$ n $$ nodes of the subtree, we have $$ T(n) = \Omega(n) $$.  
Since INORDER-TREE-WALK takes a small, constant amount of time on an empty subtree (for the test $$ x \neq $$ NIL), we have $$ T(0) = c $$ for some constant $$ c > 0 $$.
For $$ n > 0 $$, suppose that INORDER-TREE-WALK is called on a node $$ x $$ whose left subtree has $$ k $$ nodes and whose right subtree has $$ n - k - 1 $$ nodes.
The time to perform INORDER-TREE-WALK($$ x $$) is bounded by $$ T(n) \le T(k) + T(n - k - 1) + d $$ for some constant $$ d > 0 $$ that reflects an upper bound on the time to execute the body of INORDER-TREE-WALK($$ x $$).
We use the substitution method to show that $$ T(n) = O(n) $$ by proving that $$ T(n) \le (c + d) n + c $$.
For $$ n = 0 $$, we have $$ (c + d) \cdot 0 + c = c = T(0) $$.
For $$ n > 0 $$, we have

$$
\begin{align*}
    T(n) &\le T(k) + T(n - k - 1) + d \\
         &= ((c + d) k + c) + ((c + d) (n - k - 1) + c) + d \\
         &= (c + d) n + c - (c + d) + c + d \\
         &= (c + d) n + c
\end{align*}
$$

which completes the proof. $$ \blacksquare $$

## 12.2 Querying a binary search tree

### Searching

>TREE-SEARCH($$ x, \ k $$)  
>01&nbsp; if $$ x == $$ NIL or $$ k == x.key $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;return $$ x $$  
>03&nbsp; if $$ k < x.key $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;return TREE-SEARCH($$ x.left, \ k $$)  
>05&nbsp; else return TREE-SEARCH($$ x.right, \ k $$)

The procedure begins its search at the root and traces a simple path downward in the tree.
For each node $$ x $$ it encounters, it compares the key $$ k $$ with $$ x.key $$.
If the two keys are equal, the search terminates.
If $$ k $$ is smaller than $$ x.key $$, the search continues in the left subtree of $$ x $$, since the binary-search-tree property implies that $$ k $$ could not be stored in the right subtree.
Symmetrically, if $$ k $$ is larger than $$ x.key $$, the search continues in the right subtree.
The nodes encountered during the recursion form a simple path downward from the root of the tree, and thus the running time of TREE-SEARCH is $$ O(h) $$, where $$ h $$ is the height of the tree.  
We can rewrite this procedure in an iterative fashion by unrolling the recursion into a while loop.

>ITERATIVE-TREE-SEARCH($$ x, \ k $$)  
>01&nbsp; while $$ x \neq $$ NIL and $$ k \neq x.key $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ k < x.key $$  
>03&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ x = x.left $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;else $$ x = x.right $$  
>05&nbsp; return $$ x $$

### Minimum and maximum

We can always find an element in a binary search tree whose key is a minimum by following $$ left $$ child pointers from the root until we encounter a NIL.

>TREE-MINIMUM($$ x $$)  
>01&nbsp; while $$ x.left \neq $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ x = x.left $$  
>03&nbsp; return $$ x $$  

The binary-search-tree property guarantees that TREE-MINIMUM is correct.  
The pseudocode for TREE-MAXIMUM is symmetric:

>TREE-MAXIMUM($$ x $$)  
>01&nbsp; while $$ x.right \neq $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ x = x.right $$  
>03&nbsp; return $$ x $$  

Both of these procedures run in $$ O(h) $$ time on a tree of height $$ h $$ since, as in TREE-SEARCH, the sequence of nodes encountered forms a simple path downward from the root.

### Successor and predecessor

If all keys are distinct, the successor of a node $$ x $$ is the node with the smallest key greater than $$ x.key $$.
The structure of a binary search tree allows us to determine the successor of a node without ever comparing keys.

>TREE-SUCCESSOR($$ x $$)  
>01&nbsp; if $$ x.right \neq $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;return TREE-MINIMUM($$ x.right $$)  
>03&nbsp; $$ y = x.p $$  
>04&nbsp; while $$ y \neq $$ NIL and $$ x == y.right $$  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ x = y $$  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y = y.p $$  
>07&nbsp; return $$ y $$

Sometimes we need to find its successor in the sorted order determined by an inorder tree walk.
If the right subtree of node $$ x $$ is nonempty, then the successor of $$ x $$ is the leftmost node in $$ x $$'s right subtree, which we find in line 2 by calling TREE-MINIMUM($$ x.right $$).
On the other hand, if the right subtree of node $$ x $$ is empty and $$ x $$ has a successor $$ y $$, then $$ y $$ is the lowest ancestor of $$ x $$ whose left child is also an ancestor of $$ x $$.
In figure 12.1, the successor of the node with key $$ 13 $$ is the node with key $$ 15 $$.
Lines 3–7 handle this case.  
The running time of TREE-SUCCESSOR on a tree of height $$ h $$ is $$ O(h) $$, since we either follow a simple path up the tree or follow a simple path down the tree.
The procedure TREE-PREDECESSOR, which is symmetric to TREE-SUCCESSOR, also runs in time $$ O(h) $$.

In summary, we have proved the following theorem.

### Theorem 12.2

We can implement the dynamic-set operations SEARCH, MINIMUM, MAXIMUM, SUCCESSOR, and PREDECESSOR so that each one runs in $$ O(h) $$ time on a binary search tree of height $$ h $$. $$ \blacksquare $$

## 12.3 Insertion and deletion

### Insertion

The procedure TREE-INSERT takes a node $$ z $$ for which $$ z.key = v $$, $$ z.left = $$ NIL, and $$ z.right $$ = NIL.

>TREE-INSERT($$ T, \ z $$)  
>01&nbsp; $$ y = $$ NIL  
>02&nbsp; $$ x = T.root $$  
>03&nbsp; while $$ x \neq $$ NIL  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y = x $$  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ z.key < x.key $$  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ x = x.left $$  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;else $$ x = x.right $$  
>08&nbsp; $$ z.p = y $$  
>09&nbsp; if $$ y == $$ NIL  
>10&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ T.root = z $$  
>11&nbsp; elseif $$ z.key < y.key $$  
>12&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y.left = z $$  
>13&nbsp; else $$ y.right = z $$

The procedure maintains the trailing pointer $$ y $$ as the parent of $$ x $$.
After initialization, the while loop in lines 3–7 causes these two pointers to move down the tree, going left or right depending on the comparison of $$ z.key $$ with $$ x.key $$, until $$ x $$ becomes NIL.
Lines 8–13 set the pointers that cause $$ z $$ to be inserted.
Like the other primitive operations on search trees, the procedure TREE-INSERT runs in $$ O(h) $$ time on a tree of height $$ h $$.

### Deletion

The overall strategy for deleting a node $$ z $$ from a binary search tree $$ T $$ has three basic cases.

- If $$ z $$ has no children, then we simply remove it by modifying its parent to replace $$ z $$ with NIL as its child.
- If $$ z $$ has just one child, then we elevate that child to take $$ z $$'s position in the tree by modifying $$ z $$'s parent to replace $$ z $$ by $$ z $$'s child.
- If $$ z $$ has two children, then we find $$ z $$'s successor $$ y $$—which is in $$ z $$'s right subtree—and have $$ y $$ take $$ z $$'s position in the tree.
The rest of $$ z $$'s original right subtree becomes $$ y $$'s new right subtree, and $$ z $$'s left subtree becomes $$ y $$'s new left subtree.

![Desktop View](/assets/img/12-Binary-Search-Trees/Figure 12.2.png){: width="700"}
_**Figure 12.2** Deleting a node $$ z $$ from a binary search tree. **(a)** Node $$ z $$ has no left child. **(b)** Node $$ z $$ has a left child $$ l $$ but no right child. **(c)** Node $$ z $$ has two children; its left child is node $$ l $$, its right child is its successor $$ y $$, and $$ y $$'s right child is node $$ x $$. **(d)** Node $$ z $$ has two children (left child $$ l $$ and right child $$ r $$), and its successor $$ y \neq r $$ lies within the subtree rooted at $$ r $$._

The procedure for deleting a given node $$ z $$ from a binary search tree $$ T $$ takes as arguments pointers to $$ T $$ and $$ z $$.
It organizes the basic three cases by considering the four cases shown in Figure 12.2.

- If $$ z $$ has no left child, then we replace $$ z $$ by its right child.
- If $$ z $$ has one child, which is its left child, then we replace $$ z $$ by its left child.
- If $$ z $$ has both a left and a right child, and $$ z $$'s successor $$ y $$ is $$ z $$'s right child, then we replace $$ z $$ by $$ y $$, leaving $$ y $$'s right child alone.
- If $$ z $$ has both a left and a right child, and $$ y $$ lies within $$ z $$'s right subtree but is not $$ z $$'s right child, we first replace $$ y $$ by its own right child, and then we replace $$ z $$ by $$ y $$.

In order to move subtrees around within the binary search tree, we define a subroutine TRANSPLANT, which replaces one subtree as a child of its parent with another subtree.

>TRANSPLANT($$ T, \ u, \ v $$)  
>01&nbsp; if $$ u.p == $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ T.root = v $$  
>03&nbsp; elseif $$ u == u.p.left $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ u.p.left = v $$  
>05&nbsp; else $$ u.p.right = v $$  
>06&nbsp; if $$ v \neq $$ NIL  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ v.p = u.p $$

Lines 1–2 handle the case in which $$ u $$ is the root of $$ T $$.
Otherwise, $$ u $$ is either a left child or a right child of its parent.
Lines 3–4 take care of updating $$ u.p.left $$ if $$ u $$ is a left child, and line 5 updates $$ u.p.right $$ if $$ u $$ is a right child.
Lines 6–7 update $$ v.p $$ if $$ v $$ is non-NIL.

>TREE-DELETE($$ T, \ z $$)  
>01&nbsp; if $$ z.left == $$ NIL  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;TRANSPLANT($$ T, \ z, \ z.right $$)  
>03&nbsp; elseif $$ z.right == $$ NIL  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;TRANSPLANT($$ T, \ z, \ z.left $$)  
>05&nbsp; else $$ y = $$ TREE-MINIMUM($$ z.right $$)  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ y.p \neq z $$  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TRANSPLANT($$ T, \ y, \ y.right $$)  
>08&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ y.right = z.right $$  
>09&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ y.right.p = y $$  
>10&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;TRANSPLANT($$ T, \ z, \ y $$)  
>11&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y.left = z.left $$  
>12&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y.left.p = y $$

The TREE-DELETE procedure executes the four cases as follows.
Lines 1–2 handle the case in which node $$ z $$ has no left child, and lines 3–4 handle the case in which $$ z $$ has a left child but no right child.
Lines 5–12 deal with the remaining two cases, in which $$ z $$ has two children.
Line 5 finds node $$ y $$, which is the successor of $$ z $$.
Because $$ z $$ has a nonempty right subtree, its successor must be the node in that subtree with the smallest key; hence the call to TREE-MINIMUM($$ z.right $$).
As we noted before, $$ y $$ has no left child.
We want to splice $$ y $$ out of its current location, and it should replace $$ z $$ in the tree.
If $$ y $$ is $$ z $$'s right child, then lines 10–12 replace $$ z $$ as a child of its parent by $$ y $$ and replace $$ y $$'s left child by $$ z $$'s left child.
If $$ y $$ is not $$ z $$'s right child, lines 7–9 replace $$ y $$ as a child of its parent by $$ y $$'s right child, and then lines 10–12 replace $$ z $$ as a child of its parent by $$ y $$ and replace $$ y $$'s left child by $$ z $$'s left child.  
Each line of TREE-DELETE takes constant time, except for the call to TREE-MINIMUM in line 5.
Thus, TREE-DELETE runs in $$ O(h) $$ time on a tree of height $$ h $$.

In summary, we have proved the following theorem.

### Theorem 12.3

We can implement the dynamic-set operations INSERT and DELETE so that each one runs in $$ O(h) $$ time on a binary search tree of height $$ h $$. $$ \blacksquare $$

## 12.4 Randomly built binary search trees

Unfortunately, little is known about the average height of a binary search tree when both insertion and deletion are used to create it.
When the tree is created by insertion alone, the analysis becomes more tractable.
Let us therefore define a randomly built binary search tree on $$ n $$ keys as one that arises from inserting the keys in random order into an initially empty tree, where each of the $$ n! $$ permutations of the input keys is equally likely.

### Theorem 12.4

The expected height of a randomly built binary search tree on $$ n $$ distinct keys is $$ O(\lg n) $$.

**Proof**  
We denote the height of a randomly built binary search on $$ n $$ keys by $$ X_n $$, and we define the exponential height $$ Y_n = 2^{X_n} $$.
When we build a binary search tree on $$ n $$ keys, we choose one key as that of the root, and we let $$ R_n $$ denote the random variable that holds this key's rank within the set of $$ n $$ keys; that is, $$ R_n $$ holds the position that this key would occupy if the set of keys were sorted.
The value of $$ R_n $$ is equally likely to be any element of the set $$ \{ 1, \ 2, \dots, \ n \} $$.
If $$ R_n = i $$, then the left subtree of the root is a randomly built binary search tree on $$ i - 1 $$ keys, and the right subtree is a randomly built binary search tree on $$ n - i $$ keys.
Because the height of a binary tree is 1 more than the larger of the heights of the two subtrees of the root, the exponential height of a binary tree is twice the larger of the exponential heights of the two subtrees of the root.
If we know that $$ R_n = i $$, it follows that

$$
\begin{align*}
    Y_n = 2 \cdot \max(Y_{i - 1}, \ Y_{n - i})
\end{align*}
$$

As base cases, we have that $$ Y_1 = 1 $$, because the exponential height of a tree with 1 node is $$ 2^0 = 1 $$ and, for convenience, we define $$ Y_0 = 0 $$.

Next, define indicator random variables $$ Z_{n, \ 1}, \ Z_{n, \ 2}, \dots, \ Z_{n, \ n} $$, where

$$
\begin{align*}
    Z_{n, \ i} = I \{ R_n = i \}
\end{align*}
$$

Because $$ R_n $$ is equally likely to be any element of $$ \{ 1, \ 2, \dots, \ n \} $$, it follows that $$ \Pr \{ R_n = i \} = 1 / n $$ for $$ i = 1, \ 2, \dots, \ n $$, and hence, by Lemma 5.1, we have

$$
\begin{align*}
    E[Z_{n, \ i}] = 1 / n
\end{align*}
\label{eq:1}
\tag{12.1}
$$

for $$ i = 1, \ 2, \dots, \ n $$.
Because exactly one value of $$ Z_{n, \ i} $$ is $$ 1 $$ and all others are $$ 0 $$, we also have

$$
\begin{align*}
    Y_n = \sum_{i = 1}^n Z_{n, \ i} (2 \cdot \max(Y_{i - 1}, \ Y_{n - i}))
\end{align*}
$$

We shall show that $$ E[Y_n] $$ is polynomial in $$ n $$, which will ultimately imply that $$ E[X_n] = O(\lg n) $$.

We claim that 