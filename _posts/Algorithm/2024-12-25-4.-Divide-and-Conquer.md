---
title: 4. Divide-and-Conquer
# description: Short summary of the post
date: 2024-12-05 16:23
categories: [Computer Science, Algorithm]
tags: [divide-and-conquer, recurrence, maximum-subarray-problem, matrix-multiplication, strassen's-algorithm]     # TAG names should always be lowercase
math: true
pin: false
---

In the divide-and-conquer paradigm, we typically solve a problem recursively, applying three steps at each level of the recursion:

1. Divide the problem into a number of subproblems that are smaller instances of the same problem.
2. Conquer the subproblems by solving them recursively, unless the subproblem sizes are small enough.
3. Combine the solutions to the subproblems into the solution for the original problem.

### Recurrences

A recurrence is an equation or inequality that describes a function in terms of its value on smaller inputs.
This chapter offers three methods for solving recurrences:

- Substitution method: we guess a bound and then use mathematical induction to prove our guess correct.
- Recursion-tree method: it converts the recurrence into a tree whose nodes represent the costs incurred at various levels of the recursion.
- Master method: it provides bounds for recurrences of the form

$$
\begin{align*}
    T(n) = a T(n/b) + f(n)
\end{align*}
\label{eq:1}
\tag{4.1}
$$

<p class="indented-paragraph">
where $$ a \ge 1 $$, $$ b > 1 $$, and $$ f(n) $$ is a given function.
A recurrence of the form in equation \eqref{eq:1} characterizes a divide-and-conquer algorithm that creates $$ a $$ subproblems, each of which is $$ 1/b $$ the size of the original problem, and in which the divide and combine steps together take $$ f(n) $$ time.
</p>

## 4.1 The maximum-subarray problem

Suppose that you have been offered the opportunity to invest in a company.
The stock price of the company is volatile.
You are allowed to buy one unit of stock only one time and then sell it at a later date.
Also, you are allowed to learn what the price of the stock will be in the future.
Your goal is to maximize your profit.

### A brute-force solution

We can easily devise a brute-force solution to this problem: just try every possible pair of buy and sell dates in which the buy date precedes the sell date.
A period of $$ n $$ days has $$ \binom{n}{2} $$ such pairs of dates.
Since $$ \binom{n}{2} $$ is $$ \Theta(n^2) $$, and it requires a constant time to evaluate each pair of dates, this approach takes $$ \Omega(n^2) $$ time.

### Maximum subarray

Instead of looking at the daily prices, consider the daily change in price, where the change on day $$ i $$ is the difference between the prices after day $$ i - 1 $$ and after day $$ i $$.
If we treat the sequence of the daily change in price as an array $$ A $$, we now want to find the nonempty, contiguous subarray of $$ A $$ whose values have the largest sum.
We call this contiguous subarray the maximum subarray.

### A solution using divide-and-conquer

Suppose we want to find a maximum subarray of the subarray $$ A[low..high] $$.
Divide-and-conquer suggests that we divide the subarray into two subarrays of as equal size as possible.
That is, we find the midpoint, say $$ mid $$, of the subarray, and consider the subarrays $$ A[low..mid] $$ and $$ A[mid + 1..high] $$.
Then, any contiguous subarray $$ A[i..j] $$ of $$ A[low..high] $$ must lie in exactly one of the following places:

- entirely in the subarray $$ A[low..mid] $$, so that $$ low \le i \le j \le mid $$.
- entirely in the subarray $$ A[mid + 1..high] $$, so that $$ mid < i \le j \le high $$, or
- crossing the midpoint, so that $$ low \le i \le mid < j \le high $$.

Therefore, a maximum subarray of $$ A[low..high] $$ must lie in exactly one of these places.
In fact, a maximum subarray of $$ A[low..high] $$ must have the greatest sum over all subarrays entirely in $$ A[low..mid] $$, entirely in $$ A[mid + 1..high] $$, or crossing the midpoint.
We can find maximum subarrays of $$ A[low..mid] $$ and $$ A[mid + 1..high] $$ recursively, because these two subproblems are smaller instances of the problem of finding a maximum subarray.
Thus, all that is left to do is find a maximum subarray that crosses the midpoint, and take a subarray with the largest sum of the three.

We can find a maximum subarray crossing the midpoint in time linear in the size of the subarray $$ A[low..high] $$.
This problem is not a smaller instance of our original problem, because it has the added restriction that the subarray it chooses must cross the midpoint.
Any subarray crossing the midpoint is itself made of two subarrays $$ A[i..mid] $$ and $$ A[mid + 1..j] $$, where $$ low \le i \le mid $$ and $$ mid < j \le high $$.
Therefore, we just need to find maximum subarrays of the form $$ A[i..mid] $$ and $$ A[mid + 1..j] $$ and then combine them.

>FIND-MAX-CROSSING-SUBARRAY($$ A, \ low, \ mid, \ high $$)  
>01&nbsp; $$ left\text{-}sum = -\infty $$  
>02&nbsp; $$ sum = 0 $$  
>03&nbsp; for $$ i = mid $$ downto $$ low $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ sum = sum + A[i] $$  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ sum > left\text{-}sum $$  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ left\text{-}sum = sum $$  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ max\text{-}left = i $$  
>08&nbsp; $$ right\text{-}sum = -\infty $$  
>09&nbsp; $$ sum = 0 $$  
>10&nbsp; for $$ j = mid + 1 $$ to $$ high $$  
>11&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ sum = sum + A[j] $$  
>12&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ sum > right\text{-}sum $$  
>13&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ right\text{-}sum = sum $$  
>14&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ max\text{-}right = j $$  
>15&nbsp; return ($$ max\text{-}left, \ max\text{-}right, \ left\text{-}sum + right\text{-}sum $$)

This procedure works as follows.
Lines 1–7 find a maximum subarray of the left half, $$ A[low..mid] $$.
Since this subarray must contain $$ A[mid] $$, the for loop of lines 3–7 starts the index $$ i $$ at $$ mid $$ and works down to $$ low $$, so that every subarray it considers is of the form $$ A[i..mid] $$.
Whenever we find, in line 5, a subarray $$ A[i..mid] $$ with a sum of values greater than $$ left\text{-}sum $$, we update $$ left\text{-}sum $$ to this subarray's sum in line 6, and update the variable $$ max\text{-}left $$ to record this index $$ i $$ in line 7.
Lines 8–14 work analogously for the right half, $$ A[mid + 1..high] $$.
Here, the for loop of lines 10–14 considers every subarray in the form $$ A[mid + 1..j] $$.
Finally, line 15 returns the indices $$ max\text{-}left $$ and $$ max\text{-}right $$ that demarcate a maximum subarray crossing the midpoint, along with the sum $$ left\text{-}sum + right\text{-}sum $$ of the values in the subarray $$ A[max\text{-}left..max\text{-}right] $$.

If the subarray $$ A[low..high] $$ contains $$ n $$ entries (so that $$ n = high - low + 1 $$), the call FIND-MAX-CROSSING-SUBARRAY($$ A, \ low, \ mid, \ high $$) takes $$ \Theta(n) $$ time.
Since each iteration of each of the two for loops takes $$ \Theta(1) $$ time, we just need to count up how many iterations there are altogether.
The for loop of lines 3–7 makes $$ mid - low + 1 $$ iterations, and the for loop of lines 10–14 makes $$ high - mid $$ iterations, and so the total number of iterations is

$$
\begin{align*}
    (mid - low + 1) + (high - mid) &= high - low + 1 \\
                                   &= n
\end{align*}
$$

>FIND-MAXIMUM-SUBARRAY($$ A, \ low, \ high $$)  
>01&nbsp; if $$ high == low $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;return ($$low, \ high, \ A[low] $$)    
>03&nbsp; else $$ mid = \lfloor (low + high) / 2 \rfloor $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ (left\text{-}low, \ left\text{-}high, \ left\text{-}sum) = $$ FIND-MAXIMUM-SUBARRAY($$ A, \ low, \ mid $$)  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ (right\text{-}low, \ right\text{-}high, \ right\text{-}sum) = $$ FIND-MAXIMUM-SUBARRAY($$ A, \ mid + 1, \ high $$)  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ (cross\text{-}low, \ cross\text{-}high, \ cross\text{-}sum) = $$ FIND-MAX-CROSSING-SUBARRAY($$ A, \ low, \ mid, \ high $$)  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ left\text{-}sum \ge right\text{-}sum $$ and $$ left\text{-}sum \ge cross\text{-}sum $$  
>08&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return ($$ left\text{-}low, \ left\text{-}high, \ left\text{-}sum $$)  
>09&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;elseif $$ right\text{-}sum \ge left\text{-}sum $$ and $$ right\text{-}sum \ge cross\text{-}sum $$  
>10&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return ($$ right\text{-}low, \ right\text{-}high, \ right\text{-}sum $$)  
>11&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;else return ($$ cross\text{-}low, \ cross\text{-}high, \ cross\text{-}sum $$)

The initial call FIND-MAXIMUM-SUBARRAY($$ A, \ 1, \ A.length $$) will find a maximum subarray of $$ A[1..n] $$.
Similar to FIND-MAX-CROSSING-SUBARRAY, the recursive procedure FIND-MAXIMUM-SUBARRAY returns a tuple containing the indices that demarcate a maximum subarray, along with the sum of the values in a maximum subarray.
Line 1–2 tests for the base case, where the subarray has just one element, and returns a tuple with the starting and ending indices of it, along with its value.
Line 3–11 handle the recursive case.
Line 3 does the divide part, computing the index $$ mid $$ of the midpoint.
Because we know that the subarray $$ A[low..high] $$ contains at least two elements, each of the left and right subarrays ($$ A[low..mid] $$ and $$ A[mid + 1..high] $$) must have at least one element.
Lines 4 and 5 conquer by recursively finding maximum subarrays within the left and right subarrays, respectively.
Lines 6–11 form the combine part.
Line 6 finds a maximum subarray that crosses the midpoint.
Recall that finding the maximum crossing subarray is not a smaller instance of the original problem; thus we consider it to be in the combine part.
Line 7 tests whether the left subarray contains a subarray with the maximum sum, and line 8 returns that maximum subarray.
Otherwise, line 9 tests whether the right subarray contains a subarray with the maximum sum, and line 10 returns that maximum subarray.
If neither the left nor right subarray contain a subarray achieving the maximum sum, then a maximum subarray must cross the midpoint, and line 11 returns it.

### Analyzing the divide-and-conquer algorithm

Next we set up a recurrence that describes the running time of the recursive FIND-MAXIMUM-SUBARRAY procedure.
We denote by $$ T(n) $$ the running time of the procedure on a subarray of $$ n $$ elements.
The base case, when $$ n = 1 $$, is easy: line 2 takes constant time, and so

$$
\begin{align*}
    T(1) = \Theta(1)
\end{align*}
\label{eq:2}
\tag{4.2}
$$

The recursive case occurs when $$ n > 1 $$.
Each of the subproblems solved in lines 4 and 5 is on a subarray of $$ n / 2 $$ elements, and so we spend $$ T(n / 2) $$ time solving each of them.
Because we have to solve two subproblems—for the left subarray and for the right subarray—the contribution to the running time from lines 4 and 5 comes to $$ 2 T(n / 2) $$.
The call to FIND-MAX-CROSSING-SUBARRAY in line 6 takes $$ \Theta(n) $$ time.
For the recursive case, therefore, we have

$$
\begin{align*}
    T(n) &= 2 T(n / 2) + \Theta(n)
\end{align*}
\label{eq:3}
\tag{4.3}
$$

Combining equations \eqref{eq:2} and \eqref{eq:3} gives us a recurrence for the running time $$ T(n) $$ of FIND-MAXIMUM-SUBARRAY:

$$
\begin{align*}
    T(n) =
    \begin{cases}
        \Theta(1) & \text{if } n = 1 \\
        2 T(n / 2) + \Theta(n) & \text{if } n > 1
    \end{cases}
\end{align*}
\label{eq:4}
\tag{4.4}
$$

By applying the master method or recursion-tree method, we can observe that this recurrence has the solution $$ T(n) = \Theta(n \lg n) $$.

## 4.2 Strassen's algorithm for matrix multiplication

If $$ A = (a_{ij}) $$ and $$ B = (b_{ij}) $$ are square $$ n \times n $$ matrices, then in the product $$ C = A \cdot B $$, we define the entry $$ c_{ij} $$, for $$ i = 1, \ 2, \dots, \ n $$, by

$$
\begin{align*}
    c_{ij} = \sum_{k = 1}^{n} a_{ik} \cdot b_{kj}
\end{align*}
\label{eq:5}
\tag{4.5}
$$

We must compute $$ n^2 $$ matrix entries, and each is the sum of $$ n $$ values.

>SQUARE-MATRIX-MULTIPLY($$ A, \ B $$)  
>01&nbsp; $$ n = A.rows $$  
>02&nbsp; let $$ C $$ be a new $$ n \times n $$ matrix  
>03&nbsp; for $$ i = 1 $$ to $$ n $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;for $$ j = 1 $$ to $$ n $$  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ c_{ij} = 0 $$  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for $$ k = 1 $$ to $$ n $$  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ c_{ij} = c_{ij} + a_{ik} \cdot b_{kj} $$  
>08&nbsp; return $$ C $$


The SQUARE-MATRIX-MULTIPLY procedure works as follows.
The for loop of lines 3–7 computes the entries of each row $$ i $$, and within a given row $$ j $$, the for loop of lines 4–7 computes each of the entries $$ c_{ij} $$, for each column $$ j $$.
Line 5 initializes $$ c_{ij} $$ to $$ 0 $$ as we start computing the sum given in equation \eqref{eq:5}, and each iteration of the for loop of lines 6–7 adds in one more term of equation \eqref{eq:5}.
Because each of the triply-nested for loops runs exactly $$ n $$ iterations, and each execution of line 7 takes constant time, the SQUARE-MATRIX-MULTIPLY procedure takes $$ \Theta(n^3) $$ time.

### A simple divide-and-conqure algorithm

Now, before diving into Strassen's method, let's examine how to apply a divide-and-conquer algorithm to compute matrix multiplication.
To keep things simple, we assume that $$ n $$ is an exact power of 2 in each of the $$ n \times n $$ matrices.
Suppose that we partition each of $$ A $$, $$ B $$, and $$ C $$ into four $$ n/2 \times n/2 $$ matrices

$$
\begin{align*}
    A =
    \begin{pmatrix}
        A_{11} & A_{12} \\
        A_{21} & A_{22}
    \end{pmatrix}
    && B =
    \begin{pmatrix}
        B_{11} & B_{12} \\
        B_{21} & B_{22}
    \end{pmatrix}
    && C =
    \begin{pmatrix}
        C_{11} & C_{12} \\
        C_{21} & C_{22}
    \end{pmatrix}
\end{align*}
\label{eq:6}
\tag{4.6}
$$

so that we rewrite the equation $$ C = A \cdot B $$ as

$$
\begin{align*}
    \begin{pmatrix}
        C_{11} & C_{12} \\
        C_{21} & C_{22}
    \end{pmatrix}
    =
    \begin{pmatrix}
        A_{11} & A_{12} \\
        A_{21} & A_{22}
    \end{pmatrix}
    \cdot
    \begin{pmatrix}
        B_{11} & B_{12} \\
        B_{21} & B_{22}
    \end{pmatrix}
\end{align*}
\label{eq:7}
\tag{4.7}
$$

Equation \eqref{eq:7} corresponds to the four equations

$$
\begin{align*}
    C_{11} = A_{11} \cdot B_{11} + A_{12} \cdot B_{21}
\end{align*}
\label{eq:8}
\tag{4.8}
$$

$$
\begin{align*}
    C_{12} = A_{11} \cdot B_{12} + A_{12} \cdot B_{22}
\end{align*}
\label{eq:9}
\tag{4.9}
$$

$$
\begin{align*}
    C_{21} = A_{21} \cdot B_{11} + A_{22} \cdot B_{21}
\end{align*}
\label{eq:10}
\tag{4.10}
$$

$$
\begin{align*}
    C_{22} = A_{21} \cdot B_{12} + A_{22} \cdot B_{22}
\end{align*}
\label{eq:11}
\tag{4.11}
$$

Each of these four equations specifies two multiplications of $$ n/2 \times n/2 $$ matrices and the addition of their $$ n/2 \times n/2 $$ products.
We can use these equations to create a straightforward, recursive, divide-and-conquer algorithm:

>SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A, \ B $$)  
>01&nbsp; $$ n = A.rows $$  
>02&nbsp; let $$ C $$ be a new $$ n \times n $$ matrix  
>03&nbsp; if $$ n == 1 $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ c_{11} = a_{11} \cdot b_{11} $$  
>05&nbsp; else partition $$ A $$, $$ B $$, and $$ C $$ as in equations \eqref{eq:6}  
>06&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ C_{11} = $$ SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{11}, \ B_{11} $$) + SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{12}, \ B_{21} $$)  
>07&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ C_{12} = $$ SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{11}, \ B_{12} $$) + SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{12}, \ B_{22} $$)  
>08&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ C_{21} = $$ SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{21}, \ B_{11} $$) + SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{22}, \ B_{21} $$)  
>09&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ C_{22} = $$ SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{21}, \ B_{12} $$) + SQUARE-MATRIX-MULTIPLY-RECURSIVE($$ A_{22}, \ B_{22} $$)   
>10&nbsp; return $$ C $$

Now, we derive a recurrence to characterize the running time of SQUARE-MATRIX-MULTIPLY-RECURSIVE.
Let $$ T(n) $$ be the time to multiply two $$ n \times n $$ matrices using the procedure.
In the base case, when $$ n = 1 $$,

$$
\begin{align*}
    T(1) = \Theta(1)
\end{align*}
\label{eq:12}
\tag{4.12}
$$

The recursive case occurs when $$ n > 1 $$.
The partitioning of the matrices in line 5 can be executed in $$ \Theta(1) $$ time, using index calculations and referring to the original matrix.
In lines 6–9, we recursively call SQUARE-MATRIX-MULTIPLY-RECURSIVE a total of eight times.
Because each recursive call multiplies two $$ n/2 \times n/2 $$ matrices, thereby contributing $$ T(n / 2) $$ to the overall running time, the time taken by all eight recursive calls is $$ 8 T(n / 2) $$.
We also must account for the four matrix additions in lines 6–9.
Each of these matrices contains $$ n^2 / 4 $$ entries, and so each of the four matrix additions takes $$ \Theta(n^2) $$ time.
Therefore, the total time spent adding matrices in lines 6–9 is $$ \Theta(n^2) $$, and the total time for the recursive case is

$$
\begin{align*}
    T(n) &= \Theta(1) + 8 T(n / 2) + \Theta(n^2) \\
         &= 8 T(n / 2) + \Theta(n^2)
\end{align*}
\label{eq:13}
\tag{4.13}
$$

Combining equations \eqref{eq:12} and \eqref{eq:13} gives us the recurrence for the running time of SQUARE-MATRIX-MULTIPLY-RECURSIVE:

$$
\begin{align*}
    T(n) =
    \begin{cases}
        \Theta(1) & \text{if } n = 1 \\
        8 T(n / 2) + \Theta(n^2) & \text{if } n > 1
    \end{cases}
\end{align*}
\label{eq:14}
\tag{4.14}
$$

The recurrence \eqref{eq:14} has the solution $$ T(n) = \Theta(n^3) $$.
Thus, this simple divide-and-conquer approach is no faster than the straightforward SQUARE-MATRIX-MULTIPLY procedure.

### Strassen's method