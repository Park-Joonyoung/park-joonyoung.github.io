---
title: 21. Data Structures for Disjoint Sets
# description: Short summary of the post
date: 2024-12-21 15:35
categories: [Computer Science, Algorithm]
tags: [disjoint-set, union-by-rank, path-compression]     # TAG names should always be lowercase
math: true
pin: false
---

## 21.1 Disjoint-set operations

A disjoint-set data structure maintains a collection $$ \mathcal{S} = \{ S_1, \ S_2, \dots, S_k \} $$ of disjoint dynamic sets.
We identify each set by a representative, which is some member of the set.
Each element of a set is represented by an object.
Letting $$ x $$ denote an object, we wish to support the following operations:
- MAKE-SET($$ x $$) creates a new set whose only member (and thus representative) is $$ x $$.
Since the sets are disjoint, we require that $$ x $$ not already be in some other set.
- UNION($$ x, \ y $$) unites the dynamic sets that contain $$ x $$ and $$ y $$, say $$ S_x $$ and $$ S_y $$, into a new set that is the union of these two sets.
- FIND-SET($$ x $$) returns a pointer to the representative of the unique set containing $$ x $$.

Throughout this chapter, we shall analyze the running times of disjoint-set data structures in terms of two parameters: $$ n $$, the number of MAKE-SET operations, and $$ m $$, the total number of MAKE-SET, UNION, and FIND-SET operations.

### An application of disjoint-set data structures

One of the many applications of disjoint-set data structures arises in determining the connected components of an undirected graph.

>CONNECTED-COMPONENTS($$ G $$)  
>01&nbsp; for each vertex $$ v \in G.V $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;MAKE-SET($$ v $$)  
>03&nbsp; for each edge $$ (u, \ v) \in G.E $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if FIND-SET($$ u $$) $$ \neq $$ FIND-SET($$ v $$)  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UNION($$ u, \ v $$)

>SAME-COMPONENT($$ u, \ v $$)  
>01&nbsp; if FIND-SET($$ u $$) $$ == $$ FIND-SET($$ v $$)  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;return TRUE  
>03&nbsp; else return FALSE

The procedure CONNECTED-COMPONENTS initially places each vertex $$ v $$ in its own set.
Then, for each edge $$ (u, \ v) $$, it unites the sets containing $$ u $$ and $$ v $$.
After processing all the edges, two vertices are in the same connected component if and only if the corresponding objects are in the same set.
Thus, CONNECTED-COMPONENTS computes sets in such a way that the procedure SAME-COMPONENT can determine whether two vertices are in the same connected component.

## 21.2 Linked-list representation of disjoint sets

![Desktop View](/assets/img/Algorithm/21.-Data-Structures-for-Disjoint-Sets/Figure 21.1.png){: width="700"}
_**Figure 21.1** **(a)** Linked-list representations of two sets. Set $$ S_1 $$ contains a representative $$ f $$ and set $$ S_2 $$ contains a representative $$ c $$. **(b)** The result of UNION($$ g, \ e $$)._

### A simple implementation of union

We can easily construct a sequence of $$ m $$ operations on $$ n $$ objects that requires $$ \Theta(n^2) $$ time.
Suppose that we have objects $$ x_1, \ x_2, \dots, x_n $$.
We execute the sequence of $$ n $$ MAKE-SET operations followed by $$ n - 1 $$ UNION operations, so that $$ m = 2n - 1 $$.
We spend $$ \Theta(n) $$ time performing the $$ n $$ MAKE-SET operations.
Because the $$ i $$th UNION operation updates $$ i $$ objects, the total number of objects updated by all $$ n - 1 $$ UNION operations is

$$
\begin{align*}
    \sum_{i = 1}^{n - 1} i = \Theta(n^2)
\end{align*}
$$

### A weighted-union heuristic

In the worst case, the above implementation of the UNION procedure requires an average of $$ \Theta(n) $$ time per call because we may be appending a longer list onto a shorter list.
Suppose instead that each list also includes the length of the list and that we always append the shorter list onto the longer.
With this weighted-union heuristic, a single UNION operation call still take $$ \Omega(n) $$ time if both sets have $$ \Omega(n) $$ members.
However, a sequence of $$ m $$ MAKE-SET, UNION, and FIND-SET operations, $$ n $$ of which are MAKE-SET operations, takes $$ O(m + n \lg{n}) $$ time.

### Theorem 21.1

Using the linked-list representation of disjoint sets and the weighted-union heuristic, a sequence of $$ m $$ MAKE-SET, UNION, and FIND-SET operations, $$ n $$ of which are MAKE-SET operations, takes $$ O(m + n \lg{n}) $$ time.

**Proof**  
Because each UNION operation unites two disjoint sets, we perform at most $$ n - 1 $$ UNION operations over all.
Consider a particular object $$ x $$.
We know that each time $$ x $$'s pointer was updated, $$ x $$ must have started in the smaller set.
The first time $$ x $$'s pointer was updated, therefore, the resulting set must have had at least 2 members.
Similarly, the next time $$ x $$'s pointer was updated, the resulting set must have had at least 4 members.
Continuing on, we observe that for any $$ k \le n $$, after $$ x $$'s pointer has been updated $$ \lceil \lg{k} \rceil $$ times, the resulting set must have at least $$ k $$ members.
Since the largest set has at most $$ n $$ members, each object's pointer is updated at most $$ \lceil \lg{n} \rceil $$ times over all the UNION operations.
Thus the total time spent updating object pointers over all UNION operations is $$ O(n \lg{n}) $$.
We must also account for updating the $$ tail $$ pointers and the list lengths, which take only $$ \Theta(1) $$ time per UNION operation.
The total time spent in all UNION operations is thus $$ O(n \lg{n}) $$.  
The time for the entire sequence of $$ m $$ operations follows easily.
Each MAKE-SET and FIND-SET operation takes $$ O(1) $$ time, and there are $$ O(m) $$ of them.
The total time for the entire sequence is thus $$ O(m + n \lg{n}) $$. $$ \blacksquare $$

## 21.3 Disjoint-set forests

In a faster implementaion of disjoint sets, we represent sets by rooted trees (disjoint-set forest), with each node containing one member and each tree representing one set.

### Heuristics to improve the running time

By using two heuristics, we can achieve a running time that is almost linear in the total number of operations $$ m $$.
1. Union by rank: is similar to the weighted-union heuristic we used with the linked-list representation.
For each node, we maintain a rank, which is an upper bound on the height of the node.
In union by rank, we make the root with smaller rank point to the root with larger rank during a UNION operation.
2. Path compression: is used during FIND-SET operations to make each node on the find path point directly to the root.
Path compression does not change any ranks.

### Pseudocode for disjoint-set forests

With each node $$ x $$, we maintain the integer value $$ x.rank $$, which is an upper bound on the height of $$ x $$.
The UNION operaion has two cases, depending on whether the roots of the trees have equal rank.
If the roots have unequal rank, we make the root with higher rank the parent of the root with lower rank, but the ranks themselves remain unchanged.
If, instead, the roots have equal ranks, we arbitrarily choose one of the roots as the parent and increment its rank.

>MAKE-SETS($$ x $$)  
>01&nbsp; $$ x.p = x $$  
>02&nbsp; $$ x.rank = 0 $$

>UNION($$ x, \ y $$)  
>01&nbsp; LINK(FIND-SET($$ x $$), FIND-SET($$ y $$))

>LINK($$ x, \ y $$)  
>01&nbsp; if $$ x.rank > y.rank $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ y.p = x $$  
>03&nbsp; else $$ x.p = y $$  
>04&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;if $$ x.rank == y.rank $$  
>05&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$$ y.rank = y.rank + 1 $$

The following pseudocode is the FIND-SET procedure with path compression:

>FIND-SET($$ x $$)  
>01&nbsp; if $$ x \neq x.p $$  
>02&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$$ x.p = $$ FIND-SET($$ x.p $$)  
>03&nbsp; return $$ x.p $$

The FIND-SET procedure is a two-pass method: as it recurses, it makes one pass up the find path to find the root, and as the recursion unwinds, it makes a second pass back down the find path to update each node to point directly to the root.
Each call of FIND-SET($$ x $$) returns $$ x.p $$ in line 3.
If $$ x $$ is the root, then FIND-SET skips line 2 and instead returns $$ x.p $$, which is $$ x $$.
Otherwise, line 2 executes, and the recursive call with parameter $$ x.p $$ returns a pointer to the root.
Line 2 updates node $$ x $$ to point directly to the root, and line 3 returns this pointer.

### Effect of the heuristics on the running time

Alone, union by rank yields a running time of $$ \Theta(m \lg{n}) $$.
When we use both union by rank and path compression, the worst-case running time is $$ O(m \alpha(n)) $$, where $$ \alpha(n) $$ is a very slowly growing function.
In any conceivable application of a disjoint-set data structure, $$ \alpha(n) \le 4 $$; thus, we can view the running time as linear in $$ m $$ in all practical situations.

## 21.4 Analysis of union by rank with path compression

### A very quickly growing function and its very slowly growing inverse

For integers $$ k \ge 0 $$ and $$ j \ge 1 $$, we define the function $$ A_k(j) $$ as

$$
\begin{align*}
    A_k(j) =
    \begin{cases}
        j + 1 && \text{if } k = 0 \\
        A_{k - 1}^{(j + 1)}(j) && \text{if } k \ge 1
    \end{cases}
\end{align*}
$$

where $$ A_{k - 1}^{(0)}(j) = j $$ and $$ A_{k - 1}^{(i)}(j) = A_{k - 1}(A_{k - 1}^{(i - 1)}(j)) $$ for $$ i \ge 1 $$.
We refer to the parameter $$ k $$ as the level of the function $$ A $$.

### Lemma 21.2

For any integer $$ j \ge 1 $$, we have $$ A_1(j) = 2j + 1 $$.

**Proof**  
We first use induction on $$ i $$ to show that $$ A_0^{(i)} (j) = j + i $$.
For the base case, we have $$ A_0^{(0)}(j) = j = j + 0 $$.
For the inductive step, assume that $$ A_0^{(i - 1)}(j) = j + (i - 1) $$.
Then $$ A_0^{(i)}(j) = A_0(A_0^{(i - 1)}(j)) = (j + (i - 1)) + 1 = j + i $$.
Finally, we note that $$ A_1(j) = A_0^{(j + 1)}(j) = j + (j + 1) = 2j + 1 $$. $$ \blacksquare $$

### Lemma 21.3

For any integer $$ j \ge 1 $$, we have $$ A_2(j) = 2^{j + 1}(j + 1) - 1 $$.

**Proof**  
We first use induction on $$ i $$ to show that $$ A_1^{(i)}(j) = 2^i (j + 1) - 1 $$.
For the base case, we have $$ A_1^{(0)}(j) = j = 2^0(j + 1) - 1 $$.
For the inductive step, assume that $$ A_1^{(i - 1)}(j) = 2^{i - 1}(j + 1) - 1 $$.
Then $$ A_1^{(i)}(j) = A_1(A_1^{(i - 1)}(j)) = A_1(2^{i - 1} (j + 1) - 1) = 2 \cdot (2^{i - 1} (j + 1) - 1) + 1 = 2^i (j + 1) - 1 $$.
Finally, we note that $$ A_2(j) = A_1^{(j + 1)}(j) = 2^{j + 1} (j + 1) - 1 $$. $$ \blacksquare $$

Now we can see how quickly $$ A_k(j) $$ grows as level $$ k $$ increases.
From the definition of $$ A_0(k) $$ and the above lemmas, we have $$ A_3(1) = 2047 $$ and $$ A_4(1) = 16^{512} $$.  
We define the inverse of the function $$ A_k(n) $$, for integer $$ n \ge 0 $$, by

$$
\begin{align*}
    \alpha(n) = \min{\{ k : A_k(1) \ge n \}}
\end{align*}
$$

In words, $$ \alpha(n) $$ is the lowest level $$ k $$ for which $$ A_k(1) $$ is at least $$ n $$.
We see that

$$
\begin{align*}
    \alpha(n) =
    \begin{cases}
        0 && \text{for } 0 \le n \le 2 \\
        1 && \text{for } n = 3 \\
        2 && \text{for } 4 \le n \le 7 \\
        3 && \text{for } 8 \le n \le 2047 \\
        4 && \text{for } 2048 \le n \le A_4(1)
    \end{cases}
\end{align*}
$$

### Properties of ranks

### Lemma 21.4

For all nodes $$ x $$, we have $$ x.rank \le x.p.rank $$, with strict inequality if $$ x \neq x.p $$.
The value of $$ x.rank $$ is initially $$ 0 $$ and increases through time until $$ x \neq x.p $$; from then on, $$ x.rank $$ does not change.
The value of $$ x.p.rank $$ monotonically increases over time.

### Corollary 21.5

As we follow the simple path from any node toward a root, the node ranks strictly increase.

### Lemma 21.6

Every node has rank at most $$ n - 1 $$.

**Proof**  
Each node's rank starts at 0, and it increases only upon LINK operations.
Because there are at most $$ n - 1 $$ UNION operations, there are also at most $$ n - 1 $$ LINK operations.
Because each LINK operation either leaves all ranks alone or increases some node's rank by 1, all ranks are at most $$ n - 1 $$. $$ \blacksquare $$

In fact, every node has rank at most $$ \lfloor \lg{n} \rfloor $$.

### Proving the time bound

In performing the amortized analysis, we find it convenient to assume that we invoke the LINK operation rather than the UNION operation.
That is, since the parameters of the LINK procedure are pointers to two roots, we act as though we perform the appropriate FIND-SET operations separately.

### Lemma 21.7

Suppose we convert a sequence $$ S' $$ of $$ m' $$ MAKE-SET, UNION, and FIND-SET operations into a sequence $$ S $$ of $$ m $$ MAKE-SET, LINK and FIND-SET operations by turning each UNION into two FIND-SET operations followed by a LINK.
Then, if sequence $$ S $$ runs in $$ O(m \alpha(n)) $$ time, sequence $$ S' $$ runs in $$ O(m' \alpha(n)) $$ time.

**Proof**  
Since each UNION operation in sequence $$ S' $$ is converted into three operations in $$ S $$, we have $$ m' \le m \le 3m' $$.
Since $$ m = O(m') $$, an $$ O(m \alpha(n)) $$ time bound for the converted sequence $$ S $$ implies an $$ O(m' \alpha(n)) $$ time bound for the original sequence $$ S' $$. $$ \blacksquare $$

In the remainder of this section, we shall assume that the initial sequence of $$ m' $$ MAKE-SET, UNION, and FIND-SET operations has been converted to a sequence of $$ m $$ MAKE-SET, LINK, and FIND-SET operations.

### Potential function

The potential function we use assigns a potential $$ \phi_q(x) $$ to each node $$ x $$ in the disjoint-set forest after $$ q $$ operations.
We sum the node potentials for the potential of the entire forest: $$ \Phi_q = \sum_x \phi_q(x) $$, where $$ \Phi_q $$ denotes the potential of the forest after $$ q $$ operations.
The value of $$ \phi_q(x) $$ depends on whether $$ x $$ is a tree root after the $$ q $$th operation.
If it is, or if $$ x.rank = 0 $$, then $$ \phi_q(x) = \alpha(n) \cdot x.rank $$.

Now suppose that after the $$ q $$th operation, $$ x $$ is not a root and that $$ x.rank \ge 1 $$.
We need to define two auxiliary functions on $$ x $$ before we can define $$ \psi_q(x) $$.
First we define

$$
\begin{align*}
    \text{level}(x) = \max{\{ k : x.p.rank \ge A_k(x.rank) \}}
\end{align*}
$$

That is, level($$ x $$) is the greatest level $$ k $$ for which $$ A_k $$, applied to $$ x $$'s rank, is no greater than $$ x $$'s parent's rank.  
We claim that

$$
\begin{align*}
    0 \le \text{level}(x) < \alpha(n)
\end{align*}
\label{eq:1}
\tag{21.1}
$$

which we see as follows.
We have

$$
\begin{align*}
    x.p.rank &\ge x.rank + 1 && (\text{by Lemma 21.4}) \\
    &= A_0(x.rank) && (\text{by definition of } A_0(j))
\end{align*}
$$

which implies that level($$ x $$) $$ \ge 0 $$, and we have

$$
\begin{align*}
    A_{\alpha(n)}(x.rank) &\ge A_{\alpha(n)}(1) && (\text{because } A_k(j) \text{ is strictly increasing}) \\
    &\ge n && (\text{by the definition of } \alpha(n)) \\
    &> x.p.rank && (\text{by Lemma 21.6})
\end{align*}
$$

which implies that level($$ x $$) $$ < \alpha(n) $$.

The second auxiliary function applies when $$ x.rank \ge 1 $$:

$$
\begin{align*}
    \text{iter}(x) = \max{\{ i : x.p.rank \ge A_{\text{level}(x)}^{(i)}(x.rank) \}}
\end{align*}
$$

That is, iter($$ x $$) is the largest number of times we can iteratively apply $$ A_{\text{level}(x)} $$, applied initially to $$ x $$'s rank, before we get a value greater than $$ x $$'s parent's rank.  
We claim that when $$ x.rank \ge 1 $$, we have

$$
\begin{align*}
    1 \le \text{iter}(x) \le x.rank
\end{align*}
\label{eq:2}
\tag{21.2}
$$

which we see as follows.
We have

$$
\begin{align*}
    x.p.rank &\ge A_{\text{level}(x)}(x.rank) && (\text{by definition of level}(x)) \\
    &= A_{\text{level}(x)}^{(1)}(x.rank) && (\text{by definition of functional iteration})
\end{align*}
$$

which implies that iter($$ x $$) $$ \ge 1 $$, and we have

$$
\begin{align*}
    A_{\text{level}(x)}^{x.rank + 1}(x.rank) &= A_{\text{level}(x) + 1}(x.rank) && (\text{by definition of }A_k(j)) \\
    &> x.p.rank && (\text{by definition of level}(x))
\end{align*}
$$

which implies that iter($$ x $$) $$ \le x.rank $$.
Note that because $$ x.p.rank $$ monotonically increases over time, in order for iter($$ x $$) to decrease, level($$ x $$) must increase.

With these auxiliary functions in place, we are ready to define the potential of node $$ x $$ after $$ q $$ operations:

$$
\begin{align*}
    \phi_q(x) =
    \begin{cases}
        \alpha(n) \cdot x.rank && \text{if } x \text{ is a root or } x.rank = 0 \\
        (\alpha(n) - \text{level}(x)) \cdot x.rank - \text{iter}(x) && \text{if } x \text{ is not a root and } x.rank \ge 1
    \end{cases}
\end{align*}
$$

### Lemma 21.8

For every node $$ x $$, and for all operation counts $$ q $$, we have

$$
\begin{align*}
    0 \le \phi_q(x) \le \alpha(n) \cdot x.rank
\end{align*}
$$

**Proof**  
If $$ x $$ is a root or $$ x.rank = 0 $$, then $$ \phi_q(x) = \alpha(n) \cdot x.rank $$ by definition.
Now suppose that $$ x $$ is not a root and that $$ x.rank \ge 1 $$.
We obtain a lower bound on $$ \phi_q(x) $$ by maximizing level($$ x $$) and iter($$ x $$).
By the bound \eqref{eq:1}, level($$ x $$) $$ \le \alpha(n) - 1 $$, and by the bound \eqref{eq:2}, iter($$ x $$) $$ \le x.rank $$.
Thus,

$$
\begin{align*}
    \phi_q(x) &= (\alpha(n) - \text{level}(x)) \cdot x.rank - \text{iter}(x) \\
    &\ge (\alpha(n) - (\alpha(n) - 1)) \cdot x.rank - x.rank \\
    &= x.rank - x.rank \\
    &= 0
\end{align*}
$$

Similarly, we obtain an upper bound on $$ \phi_q(x) $$ by minimizing level($$ x $$) and iter($$ x $$).
By the bound \eqref{eq:1}, level($$ x $$) $$ \ge 0 $$, and by the bound \eqref{eq:2}, iter($$ x $$) $$ \ge 1 $$.
Thus,

$$
\begin{align*}
    \phi_q(x) &\le (\alpha(n) - 0) \cdot x.rank - 1 \\
    &= \alpha(n) \cdot x.rank - 1 \\
    &< \alpha(n) \cdot x.rank
\end{align*}
$$

### Corollary 21.9

If node $$ x $$ is not a root and $$ x.rank > 0 $$, then $$ \phi_q(x) < \alpha(n) \cdot x.rank $$.

### Potential changes and amortized costs of operations

### Lemma 21.10

Let $$ x $$ be a node that is not a root, and suppose that the $$ q $$th operation is either a LINK or FIND-SET.
Then after the $$ q $$th operation, $$ \phi_q(x) \le \phi_{q - 1}(x) $$.
Moreover, if $$ x.rank \ge 1 $$ and either level($$ x $$) or iter($$ x $$) changes due to the $$ q $$th operation, then $$ \phi_q(x) \le \phi_{q - 1}(x) - 1 $$.
That is, $$ x $$'s potential cannot increase, and if it has positive rank and either level($$ x $$) or iter($$ x $$) changes, then $$ x $$'s potential drops by at least 1.

**Proof**  
Because $$ x $$ is not a root, the $$ q $$th operation does not change $$ x.rank $$, and because $$ n $$ does not change after the initial $$ n $$ MAKE-SET operations, $$ \alpha(n) $$ remains unchanged as well.
Hence, these components of the formula for $$ x $$'s potential remain the same after the $$ q $$th operation.
If $$ x.rank = 0 $$, then $$ \phi_q(x) = \phi_{q - 1}(x) = 0 $$.  
Now assume that $$ x.rank \ge 1 $$.
Recall that level($$ x $$) monotonically increases over time.
If the $$ q $$th operation leaves level($$ x $$) unchanged, then iter($$ x $$) either increases or remains unchanged.
If both level($$ x $$) and iter($$ x $$) are unchanged, then $$ \phi_q(x) = \phi_{q - 1}(x) $$.
If level($$ x $$) is unchanged and iter($$ x $$) increases, then it increases by at least 1, and so $$ \phi_q(x) \le \phi_{q - 1}(x) - 1 $$.  
Finally, if the $$ q $$th operation increases level($$ x $$), it increases by at least 1, so that the value of the term $$ (\alpha(n) - \text{level}(x)) \cdot x.rank $$ drops by at least $$ x.rank $$.
Because level($$ x $$) increased, the value of iter($$ x $$) might drop, but according to the bound \eqref{eq:2}, the drop is by at most $$ x.rank - 1 $$.
Thus, the increase in potential due to the change in iter($$ x $$) is less than the decrease in potential due to the change in level($$ x $$), and we conclude that $$ \phi_q(x) \le \phi_{q - 1}(x) - 1 $$. $$ \blacksquare $$

### Lemma 21.11

The amortized cost of each MAKE-SET operation is $$ O(1) $$.

**Proof**  
Suppose that the $$ q $$th operation is MAKE-SET($$ x $$).
This operation creates node $$ x $$ with rank 0, so that $$ \phi_q(x) = 0 $$.
No other ranks or potentials change, and so $$ \Phi_q = \Phi_{q - 1} $$.
Noting that the actual cost of the MAKE-SET operation is $$ O(1) $$ completes the proof. $$ \blacksquare $$

### Lemma 21.12

The amortized cost of each LINK operation is $$ O(\alpha(n)) $$.

**Proof**  
Suppose that the $$ q $$th operation is LINK($$ x, \ y $$).
The actual cost of the LINK operation is $$ O(1) $$.
WLOG suppose that the LINK makes $$ y $$ the parent of $$ x $$.
To determine the change in potential due to the LINK, we note that the only nodes whose potentials may change are $$ x $$, $$ y $$, and the children of $$ y $$ just prior to the operation.
We shall show that the only node whose potential can increase due to the LINK is $$ y $$, and that its increase is at most $$ \alpha(n) $$:

- By Lemma 21.10, any node that is $$ y $$'s child just before the LINK cannot have its potential increase due to the LINK.
- From the definition of $$ \phi_q(x) $$, we see that, since $$ x $$ was a root just before the $$ q $$th operation, $$ \phi_{q - 1}(x) = \alpha(n) \cdot x.rank $$.
If $$ x.rank = 0 $$, then $$ \phi_q(x) = \phi_{q - 1}(x) = 0 $$.
Otherwise,

$$
\begin{align*}
    \phi_q(x) &< \alpha(n) \cdot x.rank && \text{(by Corollary 21.9)} \\
    &= \phi_{q - 1}(x)
\end{align*}
$$

and so $$ x $$'s potential decreases.
- Because $$ y $$ is a root priort to the LINK, $$ \phi_{q - 1}(y) = \alpha(n) \cdot y.rank $$.
The LINK operation leaves $$ y $$ as a root, and it either leaves $$ y $$'s rank alone or it increases $$ y $$'s rank by 1.
Therefore, either $$ \phi_q(y) = \phi_{q - 1}(y) $$ or $$ \phi_q(y) = \phi_{q - 1}(y) + \alpha(n) $$.

The increase in potential due to the LINK operation, therefore, is at most $$ \alpha(n) $$.
The amortized cost of the LINK operation is $$ O(1) + \alpha(n) = O(\alpha(n)) $$. $$ \blacksquare $$

### Lemma 21.13

The amortized cost of each FIND-SET operation is $$ O(\alpha(n)) $$.

**Proof**  
Suppose that the $$ q $$th operation is a FIND-SET and that the find path contains $$ s $$ nodes.
The actual cost of the FIND-SET operation is $$ O(s) $$.
We shall show that no node's potential increases due to the FIND-SET and that at least $$ \max(0, \ s - (\alpha(n) + 2)) $$ nodes on the find path have their potential decrease by at least 1.  
To see that no node's potential increases, we first appeal to Lemma 21.10 for all nodes other than the root.
If $$ x $$ is the root, then its potential is $$ \alpha(n) \cdot x.rank $$, which does not change.  
Now we show that at least $$ \max(0, \ s - (\alpha(n) + 2)) $$ nodes have their potential decrease by at least 1.
Let $$ x $$ be a node on the find path such that $$ x.rank > 0 $$ and $$ x $$ is followed somewhere on the find path by another node $$ y $$ that is not a root, where level($$ y $$) $$ = $$ level($$ x $$) just before the FIND-SET operation.
(Node $$ y $$ need not immediately follow $$ x $$ on the find path.)
All but at most $$ \alpha(n) + 2 $$ nodes on the find path satisfy these constraints on $$ x $$.
Those that do not satisfy them are the first node on the find path (if it has rank 0), the last node on the path (the root), and the last node $$ w $$ on the path for which level($$ w $$) $$ = k $$, for each $$ k = 0, \ 1, \ 2, \dots, \alpha(n) - 1 $$.  
Let us fix such a node $$ x $$, and we shall show that $$ x $$'s potential decreases by at least 1.
Let $$ k = \text{level}(x) = \text{level}(y) $$.
Just prior to the path compression caused by the FIND-SET, we have

$$
\begin{align*}
    x.p.rank &\ge A_k^{\text{iter}(x)}(x.rank) && (\text{by definition of iter}(x))\text{,} \\
    y.p.rank &\ge A_k(y.rank) && (\text{by definition of level}(y))\text{,} \\
    y.rank &\ge x.p.rank && (\text{by Corollary 21.5 and because } \\ & && y \text{ follows } x \text{ on the find path})
\end{align*}
$$

Putting these inequalities together and letting $$ i $$ be the value of iter($$ x $$) before path compression, we have

$$
\begin{align*}
    y.p.rank &\ge A_k(y.rank) \\
    &\ge A_k(x.p.rank) && (\text{because } A_k(j) \text{ is strictly increasing}) \\
    &\ge A_k(A_k^{\text{iter}(x)}(x.rank)) \\
    &= A_k^{(i + 1)} (x.rank)
\end{align*}
$$

Because path compression will make $$ x $$ and $$ y $$ have the same parent, we know that after path compression, $$ x.p.rank = y.p.rank $$ and that the path compression does not decrease $$ y.p.rank $$.
Since $$ x.rank $$ does not change, after path compression we have that $$ x.p.rank \ge A_k^{(i + 1)}(x.rank) $$.
Thus, path compression will cause either iter($$ x $$) to increase (to at least $$ i + 1 $$) or level($$ x $$) to increase (which occurs if iter($$ x $$) increases to at least $$ x.rank + 1 $$).
In either case, by Lemma 21.10, we have $$ \phi_q(x) \le \phi_{q - 1}(x) - 1 $$.
Hence, $$ x $$'s potential decreases by at least 1.  
The amortized cost of the FIND-SET operation is the actual cost plus the change in potential.
The actual cost is $$ O(s) $$, and we have shown that the total potential decreases by at least $$ \max(0, \ s - (\alpha(n) + 2)) $$.
The amortized cost, therefore, is at most $$ O(s) - (s - (\alpha(n) + 2)) = O(s) - s + O(\alpha(n)) = O(\alpha(n)) $$, since we can scale up the units of potential to dominate the constant hidden in $$ O(s) $$. $$ \blacksquare $$

### Theorem 2.14

A sequence of $$ m $$ MAKE-SET, UNION, and FIND-SET operations, $$ n $$ of which are MAKE-SET operations, can be performed on a disjoint-set forest with union by rank and path compression in worst-case time $$ O(m \alpha(n)) $$.

**Proof**  
Immediate from Lemmas 21.7, 21.11, 21.12, and 21.13. $$ \blacksquare $$

---

Sources:
- [Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (3rd ed.). MIT Press.](https://a.co/d/62TQVO9)