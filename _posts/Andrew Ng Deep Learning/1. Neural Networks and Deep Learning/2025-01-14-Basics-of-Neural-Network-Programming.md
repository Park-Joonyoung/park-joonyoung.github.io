---
title: 1. Basics of Neural Network Programming
# description: Short summary of the post
date: 2025-01-01 20:37
categories: [Computer Science, "Andrew Ng: Deep Learning Specialization"]
tags: [neural-network, deep-learning]     # TAG names should always be lowercase
math: true
pin: false
---

![Desktop View](/assets/img/Andrew Ng Deep Learning/1. Basics of Neural Network Programming/Figure 1.1.png){: width="700"}
_**Figure 1.1** The simple representation of a neural network._

The term deep learning refers to training neural networks.
Neural networks are formed by taking neurons and stacking them together to make hidden units (layers).
Neurons get input layer $$ X $$, which consists of input features, and predict an output $$ Y $$.
The input layer and the middle layers are densely connected.
Given enough training examples with both $$ X $$ and $$ Y $$, a neural network can figure out functions that accurately map from $$ X $$ to $$ Y $$.

The basic technical ideas behind deep learning have been already existed for decades.
However, the recent advancements in the amount of data, the computation ability (the improvements of CPUs and GPUs), and the algorithms (such as introducing a ReLU function as an activation function instead of a sigmoid function) enabled the training of large neural network models.

### Logistic Regression and Binary Classification

Logistic regression is an algorithm that is used for binary classification.




---

Sources:
- [Neural Networks and Deep Learning (Course 1 of the Deep Learning Specialization)](https://youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&si=p1sBNQSt9N7QKNm4)
- [CS230 Deep Learning](https://cs230.stanford.edu/files/)
- [DeepLearning.AI](https://www.deeplearning.ai/)