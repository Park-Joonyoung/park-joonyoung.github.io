---
title: 4. Determinants
# description: Short summary of the post
date: 2025-01-04 21:12
categories: [Mathematics, Linear Algebra]
tags: [linear-algebra, determinant]     # TAG names should always be lowercase
math: true
pin: false
---

## 4.1 Determinants of order 2

### Definition

If

$$
\begin{align*}
    A =
    \begin{pmatrix}
        a & b \\
        c & d
    \end{pmatrix}
\end{align*}
$$

is a $$ 2 \times 2 $$ matrix with entries from a field $$ F $$, then we define the determinant of $$ A $$, denoted $$ \det(A) $$ or
$$ |A| $$
, to be the scalar $$ ad - bc $$.

### Theorem 4.1

The function $$ \det: \mathsf{M}_{2 \times 2}(F) \rightarrow F $$ is a linear function of each row of a $$ 2 \times 2 $$ matrix when the other row is held fixed.
That is, if $$ u $$, $$ v $$, and $$ w $$ are in $$ \mathsf{F}^2 $$ and $$ k $$ is a scalar, then

$$
\begin{align*}
    \det
    \begin{pmatrix}
        u + kv \\
        w
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        u \\
        w
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        v \\
        w
    \end{pmatrix}
\end{align*}
$$

and

$$
\begin{align*}
    \det
    \begin{pmatrix}
        w \\
        u + kv
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        w \\
        u
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        w \\
        v
    \end{pmatrix}
\end{align*}
$$

**Proof**  
Let $$ u = (a_1, \ a_2) $$, $$ v = (b_1, \ b_2) $$, and $$ w = (c_1, \ c_2) $$ be in $$ \mathsf{F}^2 $$ and $$ k $$ be a scalar.
Then

$$
\begin{align*}
    \det
    \begin{pmatrix}
        u \\
        w
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        v \\
        w
    \end{pmatrix}
    &= \det
    \begin{pmatrix}
        a_1 & a_2 \\
        c_1 & c_2
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        b_1 & b_2 \\
        c_1 & c_2
    \end{pmatrix} \\
    &= (a_1 c_2 - a_2 c_1) + k(b_1 c_2 - b_2 c_1) \\
    &= (a_1 k b_1) c_2 + (a_2 + k b_2) c_1 \\
    &= \det
    \begin{pmatrix}
        a_1 + k b_1 & a_2 + k b_2 \\
        c_1 & c_2
    \end{pmatrix} \\
    &= \det
    \begin{pmatrix}
        u + kv \\
        w
    \end{pmatrix}
\end{align*}
$$

A similar calculation shows that

$$
\begin{align*}
    \det
    \begin{pmatrix}
        w \\
        u
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        w \\
        v
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        w \\
        u + kv
    \end{pmatrix}
\end{align*}
$$

### Theorem 4.2

Let $$ A \in \mathsf{M}_{2 \times 2}(F) $$.
Then the determinant of $$ A $$ is nonzero if and only if $$ A $$ is invertible.
Moreover, if $$ A $$ is invertible, then

$$
\begin{align*}
    A^{-1} = \frac{1}{\det(A)}
    \begin{pmatrix}
        A_{22} & -A_{12} \\
        -A_{21} & A_{11}
    \end{pmatrix}
\end{align*}
$$

**Proof**  
If $$ \det(A) \neq 0 $$, then we can define a matrix

$$
\begin{align*}
    M = \frac{1}{\det(A)}
    \begin{pmatrix}
        A_{22} & -A_{12} \\
        -A_{21} & A_{11}
    \end{pmatrix}
\end{align*}
$$

A straightforward calculation shows that $$ AM = MA = I $$, and so $$ A $$ is invertible and $$ M = A^{-1} $$.  
Conversely, suppose that $$ A $$ is invertible.
Then the rank of

$$
\begin{align*}
    A =
    \begin{pmatrix}
        A_{11} & A_{12} \\
        A_{21} & A_{22}
    \end{pmatrix}
\end{align*}
$$

must be 2.
Hence $$ A_{11} \neq 0 $$ or $$ A_{21} \neq 0 $$.
If $$ A_{11} \neq 0 $$, add $$ -A_{21} / A_{11} $$ times row 1 of $$ A $$ to row $$ 2 $$ to obtain the matrix

$$
\begin{align*}
    \begin{pmatrix}
        A_{11} & A_{12} \\
        0 & A_{22} - \frac{A_{12} A_{21}}{A_{11}}
    \end{pmatrix}
\end{align*}
$$

Because elementary row operations are rank-preserving by the corollary to Theorem 3.4, it follows that

$$
\begin{align*}
    A_{22} - \frac{A_{12} A_{21}}{A_{11}} \neq 0
\end{align*}
$$

Therefore $$ \det(A) = A_{11} A_{22} - A_{12} A_{21} \neq 0 $$.
On the other hand, if $$ A_{21} \neq 0 $$, we see that $$ \det(A) \neq 0 $$ by adding $$ -A_{11} / A_{21} $$ times row 2 of $$ A $$ to row 1 and applying a similar argument.
Thus, in either case, $$ \det(A) \neq 0 $$. $$ \blacksquare $$

## 4.2 Determinants of order $$ n $$

Given $$ A \in \mathsf{M}_{n \times n}(F) $$, for $$ n \ge 2 $$, we denote the $$ (n - 1) \times (n - 1) $$ matrix obtained from $$ A $$ by deleting row $$ i $$ and column $$ j $$ by $$ \overline{A}_{ij} $$.

### Definition

Let $$ A \in \mathsf{M}_{n \times n}(F) $$.
If $$ n = 1 $$, so that $$ A = (A_{11}) $$, we define $$ \det(A) = A_{11} $$.
For $$ n \ge 2 $$, we define $$ \det(A) $$ recursively as

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{A}_{1j})
\end{align*}
$$

The scalar $$ \det(A) $$ is called the determinant of $$ A $$.
The scalar $$ (-1)^{i + j} \det(\overline{A}_{ij}) $$ is called the cofactor of the entry of $$ A $$ in row $$ i $$, column $$ j $$.

Letting

$$
\begin{align*}
    c_{ij} = (-1)^{i + j} \det(\overline{A}_{ij})
\end{align*}
$$

denote the cofactor of the row $$ i $$, column $$ j $$ entry of $$ A $$, we can express the formula for the determinant of $$ A $$ as

$$
\begin{align*}
    \det(A) = A_{11} c_{11} + A_{12} c_{12} + \cdots + A_{1n} c_{1n}
\end{align*}
$$

This formula is called cofactor expansion along the first row of $$ A $$.

### Theorem 4.3

The determinant of an $$ n \times n $$ matrix is a linear function of each row when the remaining rows are held fixed.
That is, for $$ 1 \le r \le n $$, we have

$$
\begin{align*}
    \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        u + kv \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        u \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        v \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
\end{align*}
$$

whenever $$ k $$ is a scalar and $$ u $$, $$ v $$, and each $$ a_i $$ are row vectors in $$ \mathsf{F}^n $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
The result is immediate if $$ n = 1 $$.
Assume that for some integer $$ n \ge 2 $$ the determinant of any $$ (n - 1) \times (n - 1) $$ matrix is a linear function of each row when the remaining rows are held fixed.
Let $$ A $$ be an $$ n \times n $$ matrix with rows $$ a_1, \ a_2, \dots , a_n $$, respectively, and suppose that for some $$ r $$ $$ (1 \le r \le n) $$, we have $$ a_r = u + kv $$ for some $$ u, \ v \in \mathsf{F}^n $$ and some scalar $$ k $$.
Let $$ u = (b_1, \ b_2, \dots , b_n) $$ and $$ v = (c_1, \ c_2, \dots, c_n) $$, and let $$ B $$ and $$ C $$ be the matrices obtained from $$ A $$ by replacing row $$ r $$ of $$ A $$ by $$ u $$ and $$ v $$, respectively.
We must prove that $$ \det(A) = \det(B) + k \det(C) $$.
For $$ r > 1 $$ and $$ 1 \le j \le n $$, the rows of $$ \overline{A}_{1j} $$, $$ \overline{B}_{1j} $$, and $$ \overline{C}_{1j} $$ are the same except for row $$ r - 1 $$.
Moreover, row $$ r - 1 $$ of $$ \overline{A}_{1j} $$ is

$$
\begin{align*}
    (b_1 + k c_1, \dots, b_{j - 1} + k c_{j - 1}, \ b_{j + 1} + k c_{j + 1}, \dots, b_n + k c_n)
\end{align*}
$$

which is the sum of row $$ r - 1 $$ of $$ \overline{B}_{1j} $$ and $$ k $$ times row $$ r - 1 $$ of $$ \overline{C}_{1j} $$.
Since $$ \overline{B}_{1j} $$ and $$ \overline{C}_{1j} $$ are $$ (n - 1) \times (n - 1) $$ matrices, we have

$$
\begin{align*}
    \det(\overline{A}_{1j}) = \det(\overline{B}_{1j}) + k \det(\overline{C}_{1j})
\end{align*}
$$

by the induction hypothesis.
Thus since $$ A_{1j} = B_{1j} = C_{1j} $$, we have

$$
\begin{align*}
    \det(A) &= \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{A}_{1j}) \\
    &= \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \left[ \det(\overline{B}_{1j}) + k \det(\overline{C}_{1j}) \right] \\
    &=  \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{B}_{1j}) + k \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{C}_{1j}) \\
    &= \det(B) + k \det(C)
\end{align*}
$$

This shows that the theorem is true for $$ n \times n $$ matrices, and so the theorem is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Corollary

If $$ A \in \mathsf{M}_{n \times n}(F) $$ has a row consisting entirely of zeros, then $$ \det(A) = 0 $$.

### Lemma

Let $$ B \in \mathsf{M}_{n \times n}(F) $$, where $$ n \ge 2 $$.
If row $$ i $$ of $$ B $$ equals $$ e_k $$ for some $$ k $$ $$ (1 \le k \le n) $$, then $$ \det(B) = {(-1)}^{i + k} \det(\overline{B}_{ik}) $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
The lemma is easily proved for $$ n = 2 $$.
Assume that for some integer $$ n \ge 3 $$, the lemma is true for $$ (n - 1) \times (n - 1) $$ matrices, and let $$ B $$ be an $$ n \times n $$ matrix in which row $$ i $$ of $$ B $$ equals $$ e_k $$ for some $$ k $$ $$ (1 \le k \le n) $$.
The result follows immediately from the definition of the determinant if $$ i = 1 $$.
Suppose therefore that $$ 1 < i \le n $$.
For each $$ j \neq k $$ $$ (1 \le j \le n) $$, let $$ C_{ij} $$ denote the $$ (n - 2) \times (n - 2) $$ matrix obtained from $$ B $$ by deleting rows $$ 1 $$ and $$ i $$ and columns $$ j $$ and $$ k $$.
For each $$ j $$, row $$ i - 1 $$ of $$ \overline{B}_{1j} $$ is the following vector in $$ \mathsf{F}^{n - 1} $$:

$$
\begin{align*}
    \begin{cases}
        e_{k - 1} && \text{if } j < k \\
        \mathit{0} && \text{if } j = k \\
        e_k && \text{if } j > k
    \end{cases}
\end{align*}
$$

Hence by the induction hypothesis and the corollary to Theorem 4.3, we have

$$
\begin{align*}
    \det(\overline{B}_{1j}) =
    \begin{cases}
        {(-1)}^{(i - 1) + (k - 1)} \det(C_{ij}) && \text{if } j < k \\
        0 && \text{if } j = k \\
        {(-1)}^{(i - 1) + k} \det(C_{ij}) && \text{if } j > k
    \end{cases}
\end{align*}
$$

Therefore

$$
\begin{align*}
    \det(B) &= \sum_{j = 1}^n {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) \\
    &= \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) + \sum_{j > k} {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) \\
    &= \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \left[ {(-1)}^{(i - 1) + (k - 1)} \det(C_{ij}) \right] \\
    & \qquad + \sum_{j > k} {(-1)}^{1 + j} B_{1j} \cdot \left[ {(-1)}^{(i - 1) + k} \det(C_{ij}) \right] \\
    &= {(-1)}^{i + k} \Biggl[ \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \det(C_{ij}) \\
    & \qquad + \sum_{j > k} {(-1)}^{1 + (j - 1)} B_{1j} \cdot \det(C_{ij}) \Biggr]
\end{align*}
$$

Because the expression inside the preceding bracket is the cofactor expansion of $$ \overline{B}_{ik} $$ along the first row, it follows that

$$
\begin{align*}
    \det(B) = {(-1)}^{i + k} \det(\overline{B}_{ik})
\end{align*}
$$

This shows that the lemma is true for $$ n \times n $$ matrices, and so the lemma is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Theorem 4.4

The determinant of a square matrix can be evaluated by cofactor expansion along any row.
That is, if $$ A \in \mathsf{M}_{n \times n}(F) $$, then for any integer $$ i $$ $$ (1 \le i \le n) $$,

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

**Proof**  
Cofactor expansion along the first row of $$ A $$ gives the determinant of $$ A $$ by definition.
So the result is true if $$ i = 1 $$.
Fix $$ i > 1 $$.
Row $$ i $$ of $$ A $$ can be written as $$ \sum_{j = 1}^{n} A_{ij} e_j $$.
For $$ 1 \le j \le n $$, let $$ B_j $$ denote the matrix obtained from $$ A $$ by replacing row $$ i $$ of $$ A $$ by $$ e_j $$.
Then by Theorem 4.3 and the lemma, we have

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n A_{ij} \cdot \det(B_j) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

### Corollary

If $$ A \in \mathsf{M}_{n \times n}(F) $$ has two identical rows, then $$ \det(A) = 0 $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
Assume that for some integer $$ n \ge 3 $$, it is true for $$ (n - 1) \times (n - 1) $$ matrices, and let rows $$ r $$ and $$ s $$ of $$ A \in \mathsf{M}_{n \times n}(F) $$ be identical for $$ r \neq s $$.
Because $$ n \ge 3 $$, we can choose an integer $$ i $$ $$ (1 \le i \le n) $$ other than $$ r $$ and $$ s $$.
Now

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

by Theorem 4.4.
Since each $$ \overline{A}_{ij} $$ is an $$ (n - 1) \times (n - 1) $$ matrix with two identical rows, the induction hypothesis implies that each $$ \det(\overline{A}_{ij}) = 0 $$, and hence $$ \det(A) = 0 $$.
This completes the proof for $$ n \times n $$ matrices, and so the lemma is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Theorem 4.5

