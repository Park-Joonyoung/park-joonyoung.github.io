---
title: 4. Determinants
# description: Short summary of the post
date: 2025-01-04 21:12
categories: [Mathematics, Linear Algebra]
tags: [linear-algebra, determinant]     # TAG names should always be lowercase
math: true
pin: false
---

## 4.1 Determinants of order 2

### Definition

If

$$
\begin{align*}
    A =
    \begin{pmatrix}
        a & b \\
        c & d
    \end{pmatrix}
\end{align*}
$$

is a $$ 2 \times 2 $$ matrix with entries from a field $$ F $$, then we define the determinant of $$ A $$, denoted $$ \det(A) $$ or
$$ |A| $$
, to be the scalar $$ ad - bc $$.

### Theorem 4.1

The function $$ \det: \mathsf{M}_{2 \times 2}(F) \rightarrow F $$ is a linear function of each row of a $$ 2 \times 2 $$ matrix when the other row is held fixed.
That is, if $$ u $$, $$ v $$, and $$ w $$ are in $$ \mathsf{F}^2 $$ and $$ k $$ is a scalar, then

$$
\begin{align*}
    \det
    \begin{pmatrix}
        u + kv \\
        w
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        u \\
        w
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        v \\
        w
    \end{pmatrix}
\end{align*}
$$

and

$$
\begin{align*}
    \det
    \begin{pmatrix}
        w \\
        u + kv
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        w \\
        u
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        w \\
        v
    \end{pmatrix}
\end{align*}
$$

**Proof**  
Let $$ u = (a_1, \ a_2) $$, $$ v = (b_1, \ b_2) $$, and $$ w = (c_1, \ c_2) $$ be in $$ \mathsf{F}^2 $$ and $$ k $$ be a scalar.
Then

$$
\begin{align*}
    \det
    \begin{pmatrix}
        u \\
        w
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        v \\
        w
    \end{pmatrix}
    &= \det
    \begin{pmatrix}
        a_1 & a_2 \\
        c_1 & c_2
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        b_1 & b_2 \\
        c_1 & c_2
    \end{pmatrix} \\
    &= (a_1 c_2 - a_2 c_1) + k(b_1 c_2 - b_2 c_1) \\
    &= (a_1 k b_1) c_2 + (a_2 + k b_2) c_1 \\
    &= \det
    \begin{pmatrix}
        a_1 + k b_1 & a_2 + k b_2 \\
        c_1 & c_2
    \end{pmatrix} \\
    &= \det
    \begin{pmatrix}
        u + kv \\
        w
    \end{pmatrix}
\end{align*}
$$

A similar calculation shows that

$$
\begin{align*}
    \det
    \begin{pmatrix}
        w \\
        u
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        w \\
        v
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        w \\
        u + kv
    \end{pmatrix}
\end{align*}
$$

### Theorem 4.2

Let $$ A \in \mathsf{M}_{2 \times 2}(F) $$.
Then the determinant of $$ A $$ is nonzero if and only if $$ A $$ is invertible.
Moreover, if $$ A $$ is invertible, then

$$
\begin{align*}
    A^{-1} = \frac{1}{\det(A)}
    \begin{pmatrix}
        A_{22} & -A_{12} \\
        -A_{21} & A_{11}
    \end{pmatrix}
\end{align*}
$$

**Proof**  
If $$ \det(A) \neq 0 $$, then we can define a matrix

$$
\begin{align*}
    M = \frac{1}{\det(A)}
    \begin{pmatrix}
        A_{22} & -A_{12} \\
        -A_{21} & A_{11}
    \end{pmatrix}
\end{align*}
$$

A straightforward calculation shows that $$ AM = MA = I $$, and so $$ A $$ is invertible and $$ M = A^{-1} $$.  
Conversely, suppose that $$ A $$ is invertible.
Then the rank of

$$
\begin{align*}
    A =
    \begin{pmatrix}
        A_{11} & A_{12} \\
        A_{21} & A_{22}
    \end{pmatrix}
\end{align*}
$$

must be 2.
Hence $$ A_{11} \neq 0 $$ or $$ A_{21} \neq 0 $$.
If $$ A_{11} \neq 0 $$, add $$ -A_{21} / A_{11} $$ times row 1 of $$ A $$ to row $$ 2 $$ to obtain the matrix

$$
\begin{align*}
    \begin{pmatrix}
        A_{11} & A_{12} \\
        0 & A_{22} - \frac{A_{12} A_{21}}{A_{11}}
    \end{pmatrix}
\end{align*}
$$

Because elementary row operations are rank-preserving by the corollary to Theorem 3.4, it follows that

$$
\begin{align*}
    A_{22} - \frac{A_{12} A_{21}}{A_{11}} \neq 0
\end{align*}
$$

Therefore $$ \det(A) = A_{11} A_{22} - A_{12} A_{21} \neq 0 $$.
On the other hand, if $$ A_{21} \neq 0 $$, we see that $$ \det(A) \neq 0 $$ by adding $$ -A_{11} / A_{21} $$ times row 2 of $$ A $$ to row 1 and applying a similar argument.
Thus, in either case, $$ \det(A) \neq 0 $$. $$ \blacksquare $$

## 4.2 Determinants of order $$ n $$

Given $$ A \in \mathsf{M}_{n \times n}(F) $$, for $$ n \ge 2 $$, we denote the $$ (n - 1) \times (n - 1) $$ matrix obtained from $$ A $$ by deleting row $$ i $$ and column $$ j $$ by $$ \overline{A}_{ij} $$.

### Definition

Let $$ A \in \mathsf{M}_{n \times n}(F) $$.
If $$ n = 1 $$, so that $$ A = (A_{11}) $$, we define $$ \det(A) = A_{11} $$.
For $$ n \ge 2 $$, we define $$ \det(A) $$ recursively as

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{A}_{1j})
\end{align*}
$$

The scalar $$ \det(A) $$ is called the determinant of $$ A $$.
The scalar $$ (-1)^{i + j} \det(\overline{A}_{ij}) $$ is called the cofactor of the entry of $$ A $$ in row $$ i $$, column $$ j $$.

Letting

$$
\begin{align*}
    c_{ij} = (-1)^{i + j} \det(\overline{A}_{ij})
\end{align*}
$$

denote the cofactor of the row $$ i $$, column $$ j $$ entry of $$ A $$, we can express the formula for the determinant of $$ A $$ as

$$
\begin{align*}
    \det(A) = A_{11} c_{11} + A_{12} c_{12} + \cdots + A_{1n} c_{1n}
\end{align*}
$$

This formula is called cofactor expansion along the first row of $$ A $$.

### Theorem 4.3

The determinant of an $$ n \times n $$ matrix is a linear function of each row when the remaining rows are held fixed.
That is, for $$ 1 \le r \le n $$, we have

$$
\begin{align*}
    \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        u + kv \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        u \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
    + k \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_{r - 1} \\
        v \\
        a_{r + 1} \\
        \vdots \\
        a_n
    \end{pmatrix}
\end{align*}
$$

whenever $$ k $$ is a scalar and $$ u $$, $$ v $$, and each $$ a_i $$ are row vectors in $$ \mathsf{F}^n $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
The result is immediate if $$ n = 1 $$.
Assume that for some integer $$ n \ge 2 $$ the determinant of any $$ (n - 1) \times (n - 1) $$ matrix is a linear function of each row when the remaining rows are held fixed.
Let $$ A $$ be an $$ n \times n $$ matrix with rows $$ a_1, \ a_2, \dots , a_n $$, respectively, and suppose that for some $$ r $$ $$ (1 \le r \le n) $$, we have $$ a_r = u + kv $$ for some $$ u, \ v \in \mathsf{F}^n $$ and some scalar $$ k $$.
Let $$ u = (b_1, \ b_2, \dots , b_n) $$ and $$ v = (c_1, \ c_2, \dots, c_n) $$, and let $$ B $$ and $$ C $$ be the matrices obtained from $$ A $$ by replacing row $$ r $$ of $$ A $$ by $$ u $$ and $$ v $$, respectively.
We must prove that $$ \det(A) = \det(B) + k \det(C) $$.
For $$ r > 1 $$ and $$ 1 \le j \le n $$, the rows of $$ \overline{A}_{1j} $$, $$ \overline{B}_{1j} $$, and $$ \overline{C}_{1j} $$ are the same except for row $$ r - 1 $$.
Moreover, row $$ r - 1 $$ of $$ \overline{A}_{1j} $$ is

$$
\begin{align*}
    (b_1 + k c_1, \dots, b_{j - 1} + k c_{j - 1}, \ b_{j + 1} + k c_{j + 1}, \dots, b_n + k c_n)
\end{align*}
$$

which is the sum of row $$ r - 1 $$ of $$ \overline{B}_{1j} $$ and $$ k $$ times row $$ r - 1 $$ of $$ \overline{C}_{1j} $$.
Since $$ \overline{B}_{1j} $$ and $$ \overline{C}_{1j} $$ are $$ (n - 1) \times (n - 1) $$ matrices, we have

$$
\begin{align*}
    \det(\overline{A}_{1j}) = \det(\overline{B}_{1j}) + k \det(\overline{C}_{1j})
\end{align*}
$$

by the induction hypothesis.
Thus since $$ A_{1j} = B_{1j} = C_{1j} $$, we have

$$
\begin{align*}
    \det(A) &= \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{A}_{1j}) \\
    &= \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \left[ \det(\overline{B}_{1j}) + k \det(\overline{C}_{1j}) \right] \\
    &=  \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{B}_{1j}) + k \sum_{j = 1}^n (-1)^{1 + j} A_{1j} \cdot \det(\overline{C}_{1j}) \\
    &= \det(B) + k \det(C)
\end{align*}
$$

This shows that the theorem is true for $$ n \times n $$ matrices, and so the theorem is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Corollary

If $$ A \in \mathsf{M}_{n \times n}(F) $$ has a row consisting entirely of zeros, then $$ \det(A) = 0 $$.

### Lemma

Let $$ B \in \mathsf{M}_{n \times n}(F) $$, where $$ n \ge 2 $$.
If row $$ i $$ of $$ B $$ equals $$ e_k $$ for some $$ k $$ $$ (1 \le k \le n) $$, then $$ \det(B) = {(-1)}^{i + k} \det(\overline{B}_{ik}) $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
The lemma is easily proved for $$ n = 2 $$.
Assume that for some integer $$ n \ge 3 $$, the lemma is true for $$ (n - 1) \times (n - 1) $$ matrices, and let $$ B $$ be an $$ n \times n $$ matrix in which row $$ i $$ of $$ B $$ equals $$ e_k $$ for some $$ k $$ $$ (1 \le k \le n) $$.
The result follows immediately from the definition of the determinant if $$ i = 1 $$.
Suppose therefore that $$ 1 < i \le n $$.
For each $$ j \neq k $$ $$ (1 \le j \le n) $$, let $$ C_{ij} $$ denote the $$ (n - 2) \times (n - 2) $$ matrix obtained from $$ B $$ by deleting rows $$ 1 $$ and $$ i $$ and columns $$ j $$ and $$ k $$.
For each $$ j $$, row $$ i - 1 $$ of $$ \overline{B}_{1j} $$ is the following vector in $$ \mathsf{F}^{n - 1} $$:

$$
\begin{align*}
    \begin{cases}
        e_{k - 1} && \text{if } j < k \\
        \mathit{0} && \text{if } j = k \\
        e_k && \text{if } j > k
    \end{cases}
\end{align*}
$$

Hence by the induction hypothesis and the corollary to Theorem 4.3, we have

$$
\begin{align*}
    \det(\overline{B}_{1j}) =
    \begin{cases}
        {(-1)}^{(i - 1) + (k - 1)} \det(C_{ij}) && \text{if } j < k \\
        0 && \text{if } j = k \\
        {(-1)}^{(i - 1) + k} \det(C_{ij}) && \text{if } j > k
    \end{cases}
\end{align*}
$$

Therefore

$$
\begin{align*}
    \det(B) &= \sum_{j = 1}^n {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) \\
    &= \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) + \sum_{j > k} {(-1)}^{1 + j} B_{1j} \cdot \det(\overline{B}_{1j}) \\
    &= \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \left[ {(-1)}^{(i - 1) + (k - 1)} \det(C_{ij}) \right] \\
    & \qquad + \sum_{j > k} {(-1)}^{1 + j} B_{1j} \cdot \left[ {(-1)}^{(i - 1) + k} \det(C_{ij}) \right] \\
    &= {(-1)}^{i + k} \Biggl[ \sum_{j < k} {(-1)}^{1 + j} B_{1j} \cdot \det(C_{ij}) \\
    & \qquad + \sum_{j > k} {(-1)}^{1 + (j - 1)} B_{1j} \cdot \det(C_{ij}) \Biggr]
\end{align*}
$$

Because the expression inside the preceding bracket is the cofactor expansion of $$ \overline{B}_{ik} $$ along the first row, it follows that

$$
\begin{align*}
    \det(B) = {(-1)}^{i + k} \det(\overline{B}_{ik})
\end{align*}
$$

This shows that the lemma is true for $$ n \times n $$ matrices, and so the lemma is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Theorem 4.4

The determinant of a square matrix can be evaluated by cofactor expansion along any row.
That is, if $$ A \in \mathsf{M}_{n \times n}(F) $$, then for any integer $$ i $$ $$ (1 \le i \le n) $$,

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

**Proof**  
Cofactor expansion along the first row of $$ A $$ gives the determinant of $$ A $$ by definition.
So the result is true if $$ i = 1 $$.
Fix $$ i > 1 $$.
Row $$ i $$ of $$ A $$ can be written as $$ \sum_{j = 1}^{n} A_{ij} e_j $$.
For $$ 1 \le j \le n $$, let $$ B_j $$ denote the matrix obtained from $$ A $$ by replacing row $$ i $$ of $$ A $$ by $$ e_j $$.
Then by Theorem 4.3 and the lemma, we have

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n A_{ij} \cdot \det(B_j) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

### Corollary

If $$ A \in \mathsf{M}_{n \times n}(F) $$ has two identical rows, then $$ \det(A) = 0 $$.

**Proof**  
The proof is by mathematical induction on $$ n $$.
Assume that for some integer $$ n \ge 3 $$, it is true for $$ (n - 1) \times (n - 1) $$ matrices, and let rows $$ r $$ and $$ s $$ of $$ A \in \mathsf{M}_{n \times n}(F) $$ be identical for $$ r \neq s $$.
Because $$ n \ge 3 $$, we can choose an integer $$ i $$ $$ (1 \le i \le n) $$ other than $$ r $$ and $$ s $$.
Now

$$
\begin{align*}
    \det(A) = \sum_{j = 1}^n {(-1)}^{i + j} A_{ij} \cdot \det(\overline{A}_{ij})
\end{align*}
$$

by Theorem 4.4.
Since each $$ \overline{A}_{ij} $$ is an $$ (n - 1) \times (n - 1) $$ matrix with two identical rows, the induction hypothesis implies that each $$ \det(\overline{A}_{ij}) = 0 $$, and hence $$ \det(A) = 0 $$.
This completes the proof for $$ n \times n $$ matrices, and so the lemma is true for all square matrices by mathematical induction. $$ \blacksquare $$

### Theorem 4.5

If $$ A \in \mathsf{M}_{n \times n}(F) $$ and $$ B $$ is a matrix obtained from $$ A $$ by interchanging any two rows of $$ A $$, then $$ \det(B) = -\det(A) $$.

**Proof**  
Let the rows of $$ A \in \mathsf{M}_{n \times n}(F) $$ be $$ a_1, \ a_2, \dots, a_n $$, and let $$ B $$ be the matrix obtained from $$ A $$ by interchanging rows $$ r $$ and $$ s $$, where $$ r < s $$.
Thus

$$
\begin{align*}
    A =
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_r \\
        \vdots \\
        a_s \\
        \vdots \\
        a_n
    \end{pmatrix}
    && \text{and} && B =
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_s \\
        \vdots \\
        a_r \\
        \vdots \\
        a_n
    \end{pmatrix}
\end{align*}
$$

Consider the matrix obtained from $$ A $$ by replacing rows $$ r $$ and $$ s $$ by $$ a_r + a_s $$.
By the corollary to Theorem 4.4 and Theorem 4.3, we have

$$
\begin{align*}
    0 &= \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_r + a_s \\
        \vdots \\
        a_r + a_s \\
        \vdots \\
        a_n
    \end{pmatrix}
    = \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_r \\
        \vdots \\
        a_r + a_s \\
        \vdots \\
        a_n
    \end{pmatrix}
    + \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_s \\
        \vdots \\
        a_r + a_s \\
        \vdots \\
        a_n
    \end{pmatrix} \\
    &= \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_r \\
        \vdots \\
        a_r \\
        \vdots \\
        a_n
    \end{pmatrix}
    + \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_r \\
        \vdots \\
        a_s \\
        \vdots \\
        a_n
    \end{pmatrix}
    + \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_s \\
        \vdots \\
        a_r \\
        \vdots \\
        a_n
    \end{pmatrix}
    + \det
    \begin{pmatrix}
        a_1 \\
        \vdots \\
        a_s \\
        \vdots \\
        a_s \\
        \vdots \\
        a_n
    \end{pmatrix} \\
    &= 0 + \det(A) + \det(B) + 0
\end{align*}
$$

Therefore $$ \det(B) = -\det(A) $$. $$ \blacksquare $$

### Theorem 4.6

Let $$ A \in \mathsf{M}_{n \times n}(F) $$, and let $$ B $$ be a matrix obtained by adding a multiple of one row of $$ A $$ to another row of $$ A $$.
Then $$ \det(B) = \det(A) $$.

**Proof**  
Suppose that $$ B $$ is the $$ n \times n $$ matrix obtained from $$ A $$ by adding $$ k $$ times row $$ r $$ to row $$ s $$, where $$ r \neq s $$.
Let the rows of $$ A $$ be $$ a_1, \ a_2, \dots, a_n $$, and the rows of $$ B $$ be $$ b_1, \ b_2, \dots, b_n $$.
Then $$ b_i = a_i $$ for $$ i \neq s $$ and $$ b_s = a_s + k a_r $$.
Let $$ C $$ be the matrix obtained from $$ A $$ by replacing row $$ s $$ with $$ a_r $$.
Applying Theorem 4.3 to row $$ s $$ of $$ B $$, we obtain

$$
\begin{align*}
    \det(B) = \det(A) + k \det(C) = \det(A)
\end{align*}
$$

because $$ \det(C) = 0 $$ by the corollary to Theorem 4.4. $$ \blacksquare $$

### Corollary

If $$ A \in \mathsf{M}_{n \times n}(F) $$ has rank less than $$ n $$, then $$ \det(A) = 0 $$.

**Proof**  
If the rank of $$ A $$ is less than $$ n $$, then the rows $$ a_1, \ a_2, \dots, a_n $$ of $$ A $$ are linearly dependent.
Thus some row of $$ A $$, say, row $$ r $$, is a linear combination of the other rows.
So there exist scalars $$ c_i $$ such that

$$
\begin{align*}
    a_r = c_1 a_1 + \cdots + c_{r - 1} a_{r - 1} + c_{r + 1} a_{r + 1} + \cdots + c_n a_n
\end{align*}
$$

Let $$ B $$ be the matrix obtained from $$ A $$ by adding $$ -c_i $$ times row $$ i $$ to row $$ r $$ for each $$ i \neq r $$.
Then row $$ r $$ of $$ B $$ consists entirely of zeros, and so $$ \det(B) = 0 $$.
But by Theorem 4.6, $$ \det(B) = \det(A) $$.
Hence $$ \det(A) = 0 $$. $$ \blacksquare $$

The following rules summarize the effect of an elementary row operation on the determinant of a matrix $$ A \in \mathsf{M}_{n \times n}(F) $$.  
(a) If $$ B $$ is a matrix obtained by interchanging any two rows of $$ A $$, then $$ \det(B) = -\det(A) $$.  
(b) If $$ B $$ is a matrix obtained by multiplying a row of $$ A $$ by a nonzero scalar $$ k $$, then $$ \det(B) = k \det(A) $$.  
(c) If $$ B $$ is a matrix obtained by adding a multiple of one row of $$ A $$ to another row of $$ A $$, then $$ \det(B) = \det(A) $$.

## 4.3 Properties of determinants

The following are the facts about the determinants of elementary matrices.  
(a) If $$ E $$ is an elementary matrix obtained by interchanging any two rows of $$ I $$, then $$ \det(E) = -1 $$.  
(b) If $$ E $$ is an elementary matrix obtained by multiplying some row of $$ I $$ by the nonzero scalar $$ k $$, then $$ \det(E) = k $$.  
(c) If $$ E $$ is an elementary matrix obtained by adding a multiple of some row of $$ I $$ to another row, then $$ \det(E) = 1 $$.

### Theorem 4.7

For any $$ A, \ B \in \mathsf{M}_{n \times n}(F) $$, $$ \det(AB) = \det(A) \cdot \det(B) $$.

**Proof**  
We begin by establishing the result when $$ A $$ is an elementary matrix.
If $$ A $$ is an elementary matrix obtained by interchanging two rows of $$ I $$, then $$ \det(A) = -1 $$.
But by Theorem 3.1, $$ AB $$ is a matrix obtained by interchanging two rows of $$ B $$.
Hence by Theorem 4.5, $$ \det(AB) = -\det(B) = \det(A) \cdot \det(B) $$.
Similar arguments establish the result when $$ A $$ is an elementary matrix of type 2 or type 3.  
If $$ A $$ is an $$ n \times n $$ matrix with rank less than $$ n $$, then $$ \det(A) = 0 $$ by the corollary to Theorem 4.6.
Since $$ \text{rank}(AB) \le \text{rank}(A) < n $$ by Theorem 3.7, we have $$ \det(AB) = 0 $$.
Thus $$ \det(AB) = \det(A) \cdot \det(B) $$ in this case.  
On the other hand, if $$ A $$ has rank $$ n $$, then $$ A $$ is invertible and hence the product of elementary matrices (Corollary 3 to Theorem 3.6), say, $$ A = E_m \cdots E_2 E_1 $$.
The first paragraph of this proof shows that

$$
\begin{align*}
    \det(AB) &= \det(E_m \cdots E_2 E_1 B) \\
    &= \det(E_m) \cdot \det(E_{m - 1} \cdots E_2 E_1 B) \\
    & \ \ \vdots \\
    &= \det(E_m) \cdot \cdots \cdot \det(E_2) \cdot \det(E_1) \cdot \det(B) \\
    &= \det(E_m \cdots E_2 E_1) \cdot \det(B) \\
    &= \det(A) \cdot \det(B)
\end{align*}
$$

### Corollary

A matrix $$ A \in \mathsf{M}_{n \times n}(F) $$ is invertible if and only if $$ \det(A) \neq 0 $$.
Furthermore, if $$ A $$ is invertible, then $$ \det(A^{-1}) = \frac{1}{\det(A)} $$.

**Proof**  
If $$ A \in \mathsf{M}_{n \times n}(F) $$ is not invertible, then the rank of $$ A $$ is less than $$ n $$.
So $$ \det(A) = 0 $$ by the corollary to Theorem 4.6.
On the other hand, if $$ A \in \mathsf{M}_{n \times n}(F) $$ is invertible, then

$$
\begin{align*}
    \det(A) \cdot \det(A^{-1}) = \det(A A^{-1}) = \det(I) = 1
\end{align*}
$$

by Theorem 4.7.
Hence $$ \det(A) \neq 0 $$ and $$ \det(A^{-1}) = \frac{1}{\det(A)} $$. $$ \blacksquare $$

### Theorem 4.8

For any $$ A \in \mathsf{M}_{n \times n}(F) $$, $$ \det(A^t) = \det(A) $$.

**Proof**  
If $$ A $$ is not invertible, then $$ \text{rank}(A) < n $$.
But $$ \text{rank}(A^t) = \text{rank}(A) $$ by Corollary 2 to Theorem 3.6, and so $$ A^t $$ is not invertible.
Thus $$ \det(A^t) = 0 = \det(A) $$ in this case.  
On the other hand, if $$ A $$ is invertible, then $$ A $$ is a product of elementary matrices, say $$ A = E_m \cdots E_2 E_1 $$.
Since $$ \det(E_i) = \det({E_i}^t) $$ for every $$ i $$, by Theorem 4.7 we have

$$
\begin{align*}
    \det(A^t) &= \det({E_1}^t {E_2}^t \cdots {E_m}^t) \\
    &= \det({E_1}^t) \cdot \det({E_2}^t) \cdot \cdots \cdot \det({E_m}^t) \\
    &= \det(E_1) \cdot \det(E_2) \cdot \cdots \cdot \det(E_m) \\
    &= \det(E_m) \cdot \cdots \cdot \det(E_2) \cdot \det(E_1) \\
    &= \det(E_m \cdots E_2 E_1) \\
    &= \det(A)
\end{align*}
$$

Thus, in either case, $$ \det(A^t) = \det(A) $$. $$ \blacksquare $$

### Theorem 4.9 (Cramer's rule)

Let $$ Ax = b $$ be the matrix form of a system of $$ n $$ linear equations in $$ n $$ unknowns, where $$ x = (x_1, \ x_2, \dots, x_n)^t $$.
If $$ \det(A) \neq 0 $$, then this system has a unique solution, and for each $$ k $$ $$ (k = 1, \ 2, \dots, n) $$,

$$
\begin{align*}
    x_k = \frac{\det(M_k)}{\det(A)}
\end{align*}
$$

where $$ M_k $$ is the $$ n \times n $$ matrix obtained from $$ A $$ by replacing column $$ k $$ of $$ A $$ by $$ b $$.

**Proof**  
If $$ \det(A) \neq 0 $$, then the system $$ Ax = b $$ has a unique solution by the corollary to Theorem 4.7 and Theorem 3.10.
For each integer $$ k $$ $$ (1 \le k \le n) $$, let $$ a_k $$ denote the $$ k $$th column of $$ A $$ and $$ X_k $$ denote the matrix obtained from the $$ n \times n $$ identity matrix by replacing column $$ k $$ by $$ x $$.
Then by Theorem 2.13, $$ A X_k $$ is the $$ n \times n $$ matrix whose $$ i $$th column is

$$
\begin{align*}
    \begin{cases}
    A e_i = a_i && \text{if } i \neq k \\
    Ax = b && \text{if } i = k
    \end{cases}
\end{align*}
$$

Thus $$ A X_k = M_k $$.
Evaluating $$ X_k $$ by cofactor expansion along row $$ k $$ produces

$$
\begin{align*}
    \det(X_k) = x_k \cdot \det(I_{n - 1}) = x_k
\end{align*}
$$

Hence by Theorem 4.7,

$$
\begin{align*}
    \det(M_k) = \det(A X_k) = \det(A) \cdot \det(X_k) = \det(A) \cdot x_k
\end{align*}
$$

Therefore

$$
\begin{align*}
    x_k = {\left[ \det(A) \right]}^{-1} \cdot \det(M_k)
\end{align*}
$$